diff --git a/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/Jdk.java b/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/Jdk.java
index f66bcb51ea5..dbf4883a33f 100644
--- a/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/Jdk.java
+++ b/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/Jdk.java
@@ -23,7 +23,7 @@ import java.util.regex.Pattern;
 
 public class Jdk implements Buildable, Iterable<File> {
 
-    private static final List<String> ALLOWED_ARCHITECTURES = List.of("aarch64", "x64");
+    private static final List<String> ALLOWED_ARCHITECTURES = List.of("aarch64", "s390x", "x64");
     private static final List<String> ALLOWED_VENDORS = List.of("adoptium", "openjdk", "zulu");
     private static final List<String> ALLOWED_PLATFORMS = List.of("darwin", "linux", "windows", "mac");
     private static final Pattern VERSION_PATTERN = Pattern.compile(
diff --git a/build-tools-internal/version.properties b/build-tools-internal/version.properties
index 67d7f99d43a..5cc843fe54b 100644
--- a/build-tools-internal/version.properties
+++ b/build-tools-internal/version.properties
@@ -1,8 +1,8 @@
 elasticsearch     = 8.11.1
 lucene            = 9.8.0
 
-bundled_jdk_vendor = openjdk
-bundled_jdk = 21.0.1+12@415e3f918a1f4062a0074a2794853d0d
+bundled_jdk_vendor = adoptium
+bundled_jdk = 17.0.9+9
 # optional dependencies
 spatial4j         = 0.7
 jts               = 1.15.0
diff --git a/build-tools/src/main/java/org/elasticsearch/gradle/Architecture.java b/build-tools/src/main/java/org/elasticsearch/gradle/Architecture.java
index 34874b62d94..90d91235829 100644
--- a/build-tools/src/main/java/org/elasticsearch/gradle/Architecture.java
+++ b/build-tools/src/main/java/org/elasticsearch/gradle/Architecture.java
@@ -11,7 +11,8 @@ package org.elasticsearch.gradle;
 public enum Architecture {
 
     X64("x86_64", "linux/amd64"),
-    AARCH64("aarch64", "linux/arm64");
+    AARCH64("aarch64", "linux/arm64"),
+    S390X("s390x", "linux/s390x");
 
     public final String classifier;
     public final String dockerPlatform;
@@ -26,6 +27,7 @@ public enum Architecture {
         return switch (architecture) {
             case "amd64", "x86_64" -> X64;
             case "aarch64" -> AARCH64;
+            case "s390x" -> S390X;
             default -> throw new IllegalArgumentException("can not determine architecture from [" + architecture + "]");
         };
     }
diff --git a/distribution/archives/build.gradle b/distribution/archives/build.gradle
index dcd9fbf7330..e02cad4f9e1 100644
--- a/distribution/archives/build.gradle
+++ b/distribution/archives/build.gradle
@@ -97,6 +97,13 @@ distribution_archives {
     }
   }
 
+  linuxS390xTar {
+    archiveClassifier = 'linux-s390x'
+    content {
+      archiveFiles(modulesFiles('linux-s390x'), 'tar', 'linux', 's390x', false)
+    }
+  }
+
   linuxTar {
     archiveClassifier = 'linux-x86_64'
     content {
diff --git a/distribution/build.gradle b/distribution/build.gradle
index 90af1472deb..24179b6359d 100644
--- a/distribution/build.gradle
+++ b/distribution/build.gradle
@@ -233,7 +233,7 @@ configure(subprojects.findAll { ['archives', 'packages'].contains(it.name) }) {
   // Setup all required JDKs
   project.jdks {
     ['darwin', 'windows', 'linux'].each { platform ->
-      (platform == 'linux' || platform == 'darwin' ? ['x64', 'aarch64'] : ['x64']).each { architecture ->
+      (platform == 'linux' || platform == 'darwin' ? ['x64', 'aarch64', 's390x'] : ['x64']).each { architecture ->
         "bundled_${platform}_${architecture}" {
           it.platform = platform
           it.version = VersionProperties.bundledJdkVersion
@@ -331,7 +331,7 @@ configure(subprojects.findAll { ['archives', 'packages'].contains(it.name) }) {
             it.mode = 0644
           }
         }
-        List excludePlatforms = ['linux-x86_64', 'linux-aarch64', 'windows-x86_64', 'darwin-x86_64', 'darwin-aarch64']
+        List excludePlatforms = ['linux-x86_64', 'linux-aarch64', 'linux-s390x', 'windows-x86_64', 'darwin-x86_64', 'darwin-aarch64']
         if (platform != null) {
           excludePlatforms.remove(excludePlatforms.indexOf(platform))
         } else {
@@ -588,10 +588,12 @@ subprojects {
  'archives:darwin-tar',
  'archives:darwin-aarch64-tar',
  'archives:linux-aarch64-tar',
+ 'archives:linux-s390x-tar',
  'archives:linux-tar',
  'archives:integ-test-zip',
  'packages:rpm', 'packages:deb',
  'packages:aarch64-rpm', 'packages:aarch64-deb',
+ 'packages:s390x-rpm', 'packages:s390x-deb',
 ].forEach { subName ->
   Project subproject = project("${project.path}:${subName}")
   Configuration configuration = configurations.create(subproject.name)
diff --git a/distribution/docker/build.gradle b/distribution/docker/build.gradle
index 96e577d5635..e45cbf96b5f 100644
--- a/distribution/docker/build.gradle
+++ b/distribution/docker/build.gradle
@@ -85,33 +85,47 @@ configurations {
       attribute(ArtifactTypeDefinition.ARTIFACT_TYPE_ATTRIBUTE, ArtifactTypeDefinition.DIRECTORY_TYPE)
     }
   }
+
+  s390xDockerSource {
+    attributes {
+      attribute(ArtifactTypeDefinition.ARTIFACT_TYPE_ATTRIBUTE, ArtifactTypeDefinition.DIRECTORY_TYPE)
+    }
+  }
+
   // Iron bank images require a tarball
   aarch64DockerSourceTar
   dockerSourceTar
+  s390xDockerSourceTar
 
   log4jConfig
   tini
   allPlugins
   filebeat_aarch64
   filebeat_x86_64
+  filebeat_s390x
   metricbeat_aarch64
   metricbeat_x86_64
+  metricbeat_s390x
 }
 
-String tiniArch = Architecture.current() == Architecture.AARCH64 ? 'arm64' : 'amd64'
+String tiniArch = Architecture.current() == Architecture.AARCH64 ? 'arm64' : Architecture.current() == Architecture.S390X ? 's390x' : 'amd64'
 
 dependencies {
   aarch64DockerSource project(":distribution:archives:linux-aarch64-tar")
   aarch64DockerSourceTar project(path: ":distribution:archives:linux-aarch64-tar", configuration:"default")
   dockerSource project(":distribution:archives:linux-tar")
   dockerSourceTar project(path: ":distribution:archives:linux-tar", configuration:"default")
+  s390xDockerSource project(":distribution:archives:linux-s390x-tar")
+  s390xDockerSourceTar project(path: ":distribution:archives:linux-s390x-tar", configuration:"default")
   log4jConfig project(path: ":distribution", configuration: 'log4jConfig')
   tini "krallin:tini:0.19.0:${tiniArch}"
   allPlugins project(path: ':plugins', configuration: 'allPlugins')
   filebeat_aarch64 "beats:filebeat:${VersionProperties.elasticsearch}:linux-arm64@tar.gz"
+  filebeat_s390x "beats:filebeat:${VersionProperties.elasticsearch}:linux-s390x@tar.gz"
   filebeat_x86_64 "beats:filebeat:${VersionProperties.elasticsearch}:linux-x86_64@tar.gz"
   metricbeat_aarch64 "beats:metricbeat:${VersionProperties.elasticsearch}:linux-arm64@tar.gz"
   metricbeat_x86_64 "beats:metricbeat:${VersionProperties.elasticsearch}:linux-x86_64@tar.gz"
+  metricbeat_s390x "beats:metricbeat:${VersionProperties.elasticsearch}:linux-s390x@tar.gz"
 }
 
 ext.expansions = { Architecture architecture, DockerBase base ->
@@ -156,7 +170,7 @@ private static String toCamel(String input) {
 
 private static String taskName(String prefix, Architecture architecture, DockerBase base, String suffix) {
   return prefix +
-    (architecture == Architecture.AARCH64 ? 'Aarch64' : '') +
+    (architecture == Architecture.AARCH64 ? 'Aarch64' : architecture == Architecture.S390X ? 's390x' : '') +
     (base == DockerBase.DEFAULT ? "" : toCamel(base.name())) +
     suffix
 }
@@ -215,7 +229,7 @@ tasks.register("copyNodeKeyMaterial", Sync) {
 
 elasticsearch_distributions {
   Architecture.values().each { eachArchitecture ->
-    "docker_${eachArchitecture == Architecture.AARCH64 ? '_aarch64' : ''}" {
+    "docker_${eachArchitecture == Architecture.AARCH64 ? '_aarch64' : eachArchitecture == Architecture.S390X ? '_s390x' : ''}" {
       architecture = eachArchitecture
       type = InternalElasticsearchDistributionTypes.DOCKER
       version = VersionProperties.getElasticsearch()
@@ -271,7 +285,7 @@ tasks.named("composeUp").configure {
 
 void addBuildDockerContextTask(Architecture architecture, DockerBase base) {
   String configDirectory = base == DockerBase.IRON_BANK ? 'scripts' : 'config'
-  String arch = architecture == Architecture.AARCH64 ? '-aarch64' : ''
+  String arch = architecture == Architecture.AARCH64 ? '-aarch64' : architecture == Architecture.S390X ? '-s390x' : ''
 
   final TaskProvider<Tar> buildDockerContextTask =
     tasks.register(taskName('build', architecture, base, 'DockerContext'), Tar) {
@@ -317,7 +331,7 @@ void addTransformDockerContextTask(Architecture architecture, DockerBase base) {
     TaskProvider<Tar> buildContextTask = tasks.named(taskName("build", architecture, base, "DockerContext"))
     dependsOn(buildContextTask)
 
-    String arch = architecture == Architecture.AARCH64 ? '-aarch64' : ''
+    String arch = architecture == Architecture.AARCH64 ? '-aarch64' : architecture == Architecture.S390X ? '-s390x' : ''
     String archiveName = "elasticsearch${base.suffix}-${VersionProperties.elasticsearch}-docker-build-context${arch}"
     String distributionFolderName = "elasticsearch-${VersionProperties.elasticsearch}"
 
@@ -339,12 +353,12 @@ void addTransformDockerContextTask(Architecture architecture, DockerBase base) {
 
     // Since we replaced the remote URL in the Dockerfile, copy in the required file
     if(base == DockerBase.IRON_BANK) {
-      from(architecture == Architecture.AARCH64 ? configurations.aarch64DockerSourceTar : configurations.dockerSourceTar)
+      from(architecture == Architecture.AARCH64 ? configurations.aarch64DockerSourceTar : architecture == Architecture.S390X ? configurations.s390xDockerSourceTar : configurations.dockerSourceTar)
       from (configurations.tini) {
         rename { _ -> 'tini' }
       }
     } else {
-      from(architecture == Architecture.AARCH64 ? configurations.aarch64DockerSource : configurations.dockerSource)
+      from(architecture == Architecture.AARCH64 ? configurations.aarch64DockerSource : architecture == Architecture.S390X ? configurations.s390xDockerSource : configurations.dockerSource)
     }
 
     expansions(architecture, base).findAll { it.key != 'build_date' }.each { k, v ->
@@ -435,7 +449,7 @@ void addBuildDockerImageTask(Architecture architecture, DockerBase base) {
 
 void addBuildEssDockerImageTask(Architecture architecture) {
   DockerBase base = DockerBase.CLOUD_ESS
-  String arch = architecture == Architecture.AARCH64 ? '-aarch64' : ''
+  String arch = architecture == Architecture.AARCH64 ? '-aarch64' : architecture == Architecture.S390X ? '-s390x' : ''
   String contextDir = "${project.buildDir}/docker-context/elasticsearch${base.suffix}-${VersionProperties.elasticsearch}-docker-build-context${arch}"
 
   final TaskProvider<Sync> buildContextTask =
@@ -507,7 +521,7 @@ subprojects { Project subProject ->
   if (subProject.name.endsWith('-export')) {
     apply plugin: 'distribution'
 
-    final Architecture architecture = subProject.name.contains('aarch64-') ? Architecture.AARCH64 : Architecture.X64
+    final Architecture architecture = subProject.name.contains('aarch64-') ? Architecture.AARCH64 : subProject.name.contains('s390x-') ? Architecture.S390X : Architecture.X64
     DockerBase base = DockerBase.DEFAULT
     if (subProject.name.contains('ubi-')) {
       base = DockerBase.UBI
@@ -519,7 +533,7 @@ subprojects { Project subProject ->
       base = DockerBase.CLOUD
     }
 
-    final String arch = architecture == Architecture.AARCH64 ? '-aarch64' : ''
+    final String arch = architecture == Architecture.AARCH64 ? '-aarch64' : architecture == Architecture.S390X ? '-s390x' : ''
     final String extension = base == DockerBase.UBI ? 'ubi.tar' :
       (base == DockerBase.IRON_BANK ? 'ironbank.tar' :
         (base == DockerBase.CLOUD ? 'cloud.tar' :
@@ -553,7 +567,7 @@ subprojects { Project subProject ->
       it.setCompression(Compression.GZIP)
       it.getArchiveBaseName().set("elasticsearch${base.suffix}-${VersionProperties.elasticsearch}-docker-image")
       it.getArchiveVersion().set("")
-      it.getArchiveClassifier().set(architecture == Architecture.AARCH64 ? 'aarch64' : '')
+      it.getArchiveClassifier().set(architecture == Architecture.AARCH64 ? 'aarch64' : architecture == Architecture.S390X ? 's390x' : '')
       it.getDestinationDirectory().set(new File(project.parent.buildDir, 'distributions'))
       it.dependsOn(exportTask)
     }
diff --git a/distribution/docker/src/docker/Dockerfile b/distribution/docker/src/docker/Dockerfile
index b62fa983dd4..56e4560b9e0 100644
--- a/distribution/docker/src/docker/Dockerfile
+++ b/distribution/docker/src/docker/Dockerfile
@@ -42,7 +42,7 @@ RUN chmod 0555 /bin/tini
 
 # Install required packages to extract the Elasticsearch distribution
 <% if (docker_base == 'default' || docker_base == 'cloud') { %>
-RUN <%= retry.loop(package_manager, "${package_manager} update && DEBIAN_FRONTEND=noninteractive ${package_manager} install -y curl ") %>
+RUN <%= retry.loop(package_manager, "${package_manager} update && DEBIAN_FRONTEND=noninteractive ${package_manager} install -y curl locales make gcc") %>
 <% } else { %>
 RUN <%= retry.loop(package_manager, "${package_manager} install -y findutils tar gzip") %>
 <% } %>
@@ -58,6 +58,7 @@ RUN set -eux ; \\
     case "\$(arch)" in \\
         aarch64) tini_bin='tini-arm64' ;; \\
         x86_64)  tini_bin='tini-amd64' ;; \\
+        s390x)  tini_bin='tini-s390x' ;; \\
         *) echo >&2 ; echo >&2 "Unsupported architecture \$(arch)" ; echo >&2 ; exit 1 ;; \\
     esac ; \\
     curl --retry 10 -S -L -O https://github.com/krallin/tini/releases/download/v0.19.0/\${tini_bin} ; \\
@@ -76,7 +77,7 @@ WORKDIR /usr/share/elasticsearch
   // Iron Bank always copies the local artifact. It uses `arch` from the
   // template context variables.
 %>
-COPY elasticsearch-${version}-linux-${arch}.tar.gz /tmp/elasticsearch.tar.gz
++COPY ../../../archives/linux-s390x-tar/build/distributions/elasticsearch-${version}-linux-${arch}.tar.gz /tmp/elasticsearch.tar.gz
 <% } else {
   // Fetch the appropriate Elasticsearch distribution for this architecture.
   // Keep this command on one line - it is replaced with a `COPY` during local builds.
@@ -108,10 +109,21 @@ RUN sed -i -e 's/ES_DISTRIBUTION_TYPE=tar/ES_DISTRIBUTION_TYPE=docker/' bin/elas
     mv config/log4j2.docker.properties config/log4j2.properties && \\
     find . -type d -exec chmod 0555 {} + && \\
     find . -type f -exec chmod 0444 {} + && \\
-    chmod 0555 bin/* jdk/bin/* jdk/lib/jspawnhelper modules/x-pack-ml/platform/linux-*/bin/* && \\
+    chmod 0555 bin/* jdk/bin/* jdk/lib/jspawnhelper && \\
     chmod 0775 bin config config/jvm.options.d data logs plugins && \\
     find config -type f -exec chmod 0664 {} +
 
+# Rebuild jansi native lib so that it uses the image's glibc
+RUN mkdir jansi_tmp && cd jansi_tmp && \\
+  curl --retry 10 -S -L -O https://github.com/fusesource/jansi/archive/refs/tags/jansi-2.4.0.tar.gz && \\
+  tar -zxf jansi-2.4.0.tar.gz --strip-components=1 && \\
+  make clean-native native OS_NAME=Linux OS_ARCH=s390x && \\
+  curl --retry 10 -S -L -O https://repo1.maven.org/maven2/org/fusesource/jansi/jansi/2.4.0/jansi-2.4.0.jar && \\
+  mkdir -p org/fusesource/jansi/internal/native/Linux/s390x && \\
+  cp target/native-Linux-s390x/libjansi.so org/fusesource/jansi/internal/native/Linux/s390x/ && \\
+  ../jdk/bin/jar uf ../lib/tools/ansi-console/jansi-2.4.0.jar org/fusesource/jansi/internal/native/Linux/s390x/libjansi.so && \\
+  cd ../ && rm -rf jansi_tmp
+
 <% if (docker_base == "cloud") { %>
 COPY filebeat-${version}.tar.gz metricbeat-${version}.tar.gz /tmp/
 RUN set -eux ; \\
diff --git a/distribution/docker/src/docker/config/elasticsearch.yml b/distribution/docker/src/docker/config/elasticsearch.yml
index 50b154702b9..69d740350b7 100644
--- a/distribution/docker/src/docker/config/elasticsearch.yml
+++ b/distribution/docker/src/docker/config/elasticsearch.yml
@@ -1,2 +1,3 @@
 cluster.name: "docker-cluster"
 network.host: 0.0.0.0
+xpack.ml.enabled: false
diff --git a/distribution/packages/build.gradle b/distribution/packages/build.gradle
index 1d0f77bd359..949717c9838 100644
--- a/distribution/packages/build.gradle
+++ b/distribution/packages/build.gradle
@@ -101,6 +101,8 @@ def commonPackageConfig(String type, String architecture) {
     if (type == 'deb') {
       if (architecture == 'x64') {
         arch('amd64')
+      } else if (architecture == 's390x') {
+        arch('s390x')
       } else {
         assert architecture == 'aarch64': architecture
         arch('arm64')
@@ -109,13 +111,15 @@ def commonPackageConfig(String type, String architecture) {
       assert type == 'rpm': type
       if (architecture == 'x64') {
         arch('X86_64')
+      } else if (architecture == 's390x') {
+        arch('s390x')
       } else {
         assert architecture == 'aarch64': architecture
         arch('aarch64')
       }
     }
     // Follow elasticsearch's file naming convention
-    String prefix = "${architecture == 'aarch64' ? 'aarch64-' : ''}${type}"
+    String prefix = "${architecture == 'aarch64' ? 'aarch64-' : 's390x' ? 's390x-' : ''}${type}"
     destinationDirectory = file("${prefix}/build/distributions")
     archiveFileName.value(project.provider({ "${packageName}-${project.version}-${archString}.${type}" }))
     String packagingFiles = "build/packaging/${type}"
@@ -330,6 +334,10 @@ tasks.register('buildAarch64Deb', Deb) {
   configure(commonDebConfig('aarch64'))
 }
 
+tasks.register('buildS390xDeb', Deb) {
+  configure(commonDebConfig('s390x'))
+}
+
 tasks.register('buildDeb', Deb) {
   configure(commonDebConfig('x64'))
 }
@@ -363,6 +371,10 @@ tasks.register('buildAarch64Rpm', Rpm) {
   configure(commonRpmConfig('aarch64'))
 }
 
+tasks.register('buildS390xRpm', Rpm) {
+  configure(commonRpmConfig('s390x'))
+}
+
 tasks.register('buildRpm', Rpm) {
   configure(commonRpmConfig('x64'))
 }
diff --git a/gradle/verification-metadata.xml b/gradle/verification-metadata.xml
index b032c19e83a..7fa5e339821 100644
--- a/gradle/verification-metadata.xml
+++ b/gradle/verification-metadata.xml
@@ -36,6 +36,11 @@
             <sha256 value="d083479ca927dce2f586f779373d895e8bf668c632505740279390384edf03fa" origin="Generated by Gradle"/>
          </artifact>
       </component>
+      <component group="adoptium_17" name="linux" version="17.0.9">
+         <artifact name="linux-17.0.9-s390x.tar.gz">
+            <sha256 value="45562179b9b623331f741a3a12b298a4d4b901555862148963c86ae7b10d320a" origin="Generated by Gradle"/>
+         </artifact>
+      </component>
       <component group="com.github.breskeby" name="gradle-ospackage-plugin" version="2da19425133">
          <artifact name="gradle-ospackage-plugin-2da19425133.jar">
             <sha256 value="452e01bc961259e2a0f5d6f193a03cc8d29f560a433f7c8066158c97d3327af9" origin="Generated by Gradle"/>
diff --git a/server/src/main/java/org/elasticsearch/bootstrap/BootstrapChecks.java b/server/src/main/java/org/elasticsearch/bootstrap/BootstrapChecks.java
index a99ed225b24..6c9dea91976 100644
--- a/server/src/main/java/org/elasticsearch/bootstrap/BootstrapChecks.java
+++ b/server/src/main/java/org/elasticsearch/bootstrap/BootstrapChecks.java
@@ -210,7 +210,6 @@ final class BootstrapChecks {
         checks.add(new EarlyAccessCheck());
         checks.add(new AllPermissionCheck());
         checks.add(new DiscoveryConfiguredCheck());
-        checks.add(new ByteOrderCheck());
         return Collections.unmodifiableList(checks);
     }
 
diff --git a/server/src/main/java/org/elasticsearch/bootstrap/SystemCallFilter.java b/server/src/main/java/org/elasticsearch/bootstrap/SystemCallFilter.java
index 0ab855d1d5f..efb2efb49f6 100644
--- a/server/src/main/java/org/elasticsearch/bootstrap/SystemCallFilter.java
+++ b/server/src/main/java/org/elasticsearch/bootstrap/SystemCallFilter.java
@@ -216,7 +216,9 @@ final class SystemCallFilter {
             "amd64",
             new Arch(0xC000003E, 0x3FFFFFFF, 57, 58, 59, 322, 317),
             "aarch64",
-            new Arch(0xC00000B7, 0xFFFFFFFF, 1079, 1071, 221, 281, 277)
+            new Arch(0xC00000B7, 0xFFFFFFFF, 1079, 1071, 221, 281, 277),
+            "s390x",
+            new Arch(0x80000016, 0x3FFFFFFF, 2, 190, 11, 354, 348)
         );
     }
 
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/AbstractBytesReference.java b/server/src/main/java/org/elasticsearch/common/bytes/AbstractBytesReference.java
index f29423757c0..23909e3b3c8 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/AbstractBytesReference.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/AbstractBytesReference.java
@@ -37,6 +37,18 @@ public abstract class AbstractBytesReference implements BytesReference {
         return (get(index) & 0xFF) << 24 | (get(index + 1) & 0xFF) << 16 | (get(index + 2) & 0xFF) << 8 | get(index + 3) & 0xFF;
     }
 
+    @Override
+    public long getLong(int index) {
+        return (long) (get(index) & 0xFF) << 56 | (long) (get(index + 1) & 0xFF) << 48 | (long) (get(index + 2) & 0xFF) << 40
+            | (long) (get(index + 3) & 0xFF) << 32 | (long) (get(index + 4) & 0xFF) << 24 | (get(index + 5) & 0xFF) << 16 | (get(index + 6)
+            & 0xFF) << 8 | get(index + 7) & 0xFF;
+    }
+
+    @Override
+    public double getDouble(int index) {
+        return Double.longBitsToDouble(getLong(index));
+    }
+
     @Override
     public int getIntLE(int index) {
         return (get(index + 3) & 0xFF) << 24 | (get(index + 2) & 0xFF) << 16 | (get(index + 1) & 0xFF) << 8 | get(index) & 0xFF;
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/BytesArray.java b/server/src/main/java/org/elasticsearch/common/bytes/BytesArray.java
index d01ef44916c..1da6fd48c26 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/BytesArray.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/BytesArray.java
@@ -126,6 +126,21 @@ public final class BytesArray extends AbstractBytesReference {
         os.write(bytes, offset, length);
     }
 
+    @Override
+    public int getInt(int index) {
+        return ByteUtils.readIntBE(bytes, offset + index);
+    }
+
+    @Override
+    public long getLong(int index) {
+        return ByteUtils.readLongBE(bytes, offset + index);
+    }
+
+    @Override
+    public double getDouble(int index) {
+        return ByteUtils.readDoubleBE(bytes, offset + index);
+    }
+
     @Override
     public int getIntLE(int index) {
         return ByteUtils.readIntLE(bytes, offset + index);
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java b/server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java
index f667bd1a490..2524f265779 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java
@@ -124,6 +124,16 @@ public interface BytesReference extends Comparable<BytesReference>, ToXContentFr
      */
     int getInt(int index);
 
+    /**
+     * Returns the long read from the 8 bytes (BE) starting at the given index.
+     */
+    long getLong(int index);
+
+    /**
+     * Returns the double read from the 8 bytes (BE) starting at the given index.
+     */
+    double getDouble(int index);
+
     /**
      * Returns the integer read from the 4 bytes (LE) starting at the given index.
      */
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java b/server/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java
index 09ccab35d1e..3911a94f3a2 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java
@@ -220,6 +220,42 @@ public final class CompositeBytesReference extends AbstractBytesReference {
         return ramBytesUsed;
     }
 
+    @Override
+    public int getInt(int index) {
+        int i = getOffsetIndex(index);
+        int idx = index - offsets[i];
+        int end = idx + 4;
+        BytesReference wholeIntLivesHere = references[i];
+        if (end <= wholeIntLivesHere.length()) {
+            return wholeIntLivesHere.getInt(idx);
+        }
+        return super.getInt(index);
+    }
+
+    @Override
+    public long getLong(int index) {
+        int i = getOffsetIndex(index);
+        int idx = index - offsets[i];
+        int end = idx + 8;
+        BytesReference wholeLongsLivesHere = references[i];
+        if (end <= wholeLongsLivesHere.length()) {
+            return wholeLongsLivesHere.getLong(idx);
+        }
+        return super.getLong(index);
+    }
+
+    @Override
+    public double getDouble(int index) {
+        int i = getOffsetIndex(index);
+        int idx = index - offsets[i];
+        int end = idx + 8;
+        BytesReference wholeDoublesLivesHere = references[i];
+        if (end <= wholeDoublesLivesHere.length()) {
+            return wholeDoublesLivesHere.getDouble(idx);
+        }
+        return super.getDouble(index);
+    }
+
     @Override
     public int getIntLE(int index) {
         int i = getOffsetIndex(index);
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/ReleasableBytesReference.java b/server/src/main/java/org/elasticsearch/common/bytes/ReleasableBytesReference.java
index 337e4cd28c2..e8df274572e 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/ReleasableBytesReference.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/ReleasableBytesReference.java
@@ -104,6 +104,18 @@ public final class ReleasableBytesReference implements RefCounted, Releasable, B
         return delegate.getInt(index);
     }
 
+    @Override
+    public long getLong(int index) {
+        assert hasReferences();
+        return delegate.getLong(index);
+    }
+
+    @Override
+    public double getDouble(int index) {
+        assert hasReferences();
+        return delegate.getDouble(index);
+    }
+
     @Override
     public int getIntLE(int index) {
         assert hasReferences();
diff --git a/server/src/main/java/org/elasticsearch/common/filesystem/LinuxFileSystemNatives.java b/server/src/main/java/org/elasticsearch/common/filesystem/LinuxFileSystemNatives.java
index b40fb5c2e14..99208f09b6f 100644
--- a/server/src/main/java/org/elasticsearch/common/filesystem/LinuxFileSystemNatives.java
+++ b/server/src/main/java/org/elasticsearch/common/filesystem/LinuxFileSystemNatives.java
@@ -117,11 +117,11 @@ final class LinuxFileSystemNatives implements FileSystemNatives.Provider {
             "__pad0",
             "st_rdev",
             "st_size",
-            "st_blksize",
-            "st_blocks",
             "st_atim",
             "st_mtim",
             "st_ctim",
+            "st_blksize",
+            "st_blocks",
             "__glibc_reserved0",
             "__glibc_reserved1",
             "__glibc_reserved2" }
diff --git a/server/src/main/java/org/elasticsearch/common/util/ByteUtils.java b/server/src/main/java/org/elasticsearch/common/util/ByteUtils.java
index 06be38ce34e..3299c34f915 100644
--- a/server/src/main/java/org/elasticsearch/common/util/ByteUtils.java
+++ b/server/src/main/java/org/elasticsearch/common/util/ByteUtils.java
@@ -79,6 +79,16 @@ public enum ByteUtils {
         return (long) BIG_ENDIAN_LONG.get(arr, offset);
     }
 
+    /**
+     * Converts a byte array written in little big format to a double.
+     *
+     * @param arr The byte array to read from in big endian layout
+     * @param offset The offset where in the array to read from
+     */
+    public static double readDoubleBE(byte[] arr, int offset) {
+        return Double.longBitsToDouble(readLongBE(arr, offset));
+    }
+
     /**
      * Converts an int to a byte array in little endian format.
      *
diff --git a/server/src/main/java/org/elasticsearch/common/util/ReleasableDoubleArray.java b/server/src/main/java/org/elasticsearch/common/util/ReleasableDoubleArray.java
index ecee3618995..e6d6df4d773 100644
--- a/server/src/main/java/org/elasticsearch/common/util/ReleasableDoubleArray.java
+++ b/server/src/main/java/org/elasticsearch/common/util/ReleasableDoubleArray.java
@@ -40,7 +40,7 @@ class ReleasableDoubleArray implements DoubleArray {
             // We can't serialize messages longer than 2gb anyway
             throw new ArrayIndexOutOfBoundsException();
         }
-        return ref.getDoubleLE((int) index * Long.BYTES);
+        return ref.getDouble((int) index * Long.BYTES);
     }
 
     @Override
diff --git a/server/src/main/java/org/elasticsearch/common/util/ReleasableIntArray.java b/server/src/main/java/org/elasticsearch/common/util/ReleasableIntArray.java
index 9dbe6bc0771..54ae8ebdc4e 100644
--- a/server/src/main/java/org/elasticsearch/common/util/ReleasableIntArray.java
+++ b/server/src/main/java/org/elasticsearch/common/util/ReleasableIntArray.java
@@ -40,7 +40,7 @@ class ReleasableIntArray implements IntArray {
             // We can't serialize messages longer than 2gb anyway
             throw new ArrayIndexOutOfBoundsException();
         }
-        return ref.getIntLE((int) index * 4);
+        return ref.getInt((int) index * 4);
     }
 
     @Override
diff --git a/server/src/main/java/org/elasticsearch/common/util/ReleasableLongArray.java b/server/src/main/java/org/elasticsearch/common/util/ReleasableLongArray.java
index 44764ea1e17..35a795db0ea 100644
--- a/server/src/main/java/org/elasticsearch/common/util/ReleasableLongArray.java
+++ b/server/src/main/java/org/elasticsearch/common/util/ReleasableLongArray.java
@@ -41,7 +41,7 @@ public class ReleasableLongArray implements LongArray {
             // We can't serialize messages longer than 2gb anyway
             throw new ArrayIndexOutOfBoundsException();
         }
-        return ref.getLongLE((int) index * Long.BYTES);
+        return ref.getLong((int) index * Long.BYTES);
     }
 
     @Override
diff --git a/server/src/test/java/org/elasticsearch/common/bytes/BytesArrayTests.java b/server/src/test/java/org/elasticsearch/common/bytes/BytesArrayTests.java
index d75cd363925..120bbe32c9c 100644
--- a/server/src/test/java/org/elasticsearch/common/bytes/BytesArrayTests.java
+++ b/server/src/test/java/org/elasticsearch/common/bytes/BytesArrayTests.java
@@ -100,4 +100,47 @@ public class BytesArrayTests extends AbstractBytesReferenceTestCase {
         Exception e = expectThrows(ArrayIndexOutOfBoundsException.class, () -> ref.getDoubleLE(9));
         assertThat(e.getMessage(), equalTo("Index 9 out of bounds for length 9"));
     }
+
+    public void testGetInt() {
+        BytesReference ref = new BytesArray(new byte[] { 0x00, 0x01, 0x00, 0x12, 0x10, 0x12 }, 1, 5);
+        assertThat(ref.getInt(0), equalTo(0x01001210));
+        assertThat(ref.getInt(1), equalTo(0x00121012));
+        Exception e = expectThrows(ArrayIndexOutOfBoundsException.class, () -> ref.getIntLE(2));
+        assertThat(e.getMessage(), equalTo("Index 3 out of bounds for length 3"));
+        /*
+         * Wait. 3!? The array has length 6. Well, the var handle stuff
+         * for arrays just subtracts three - because that's one more than
+         * the number of bytes in an int. Get it? I'm not sure I do either....
+         */
+    }
+
+    public void testGetLong() {
+        // first 8 bytes = 888, second 8 bytes = Long.MAX_VALUE
+        // tag::noformat
+        byte[] array = new byte[] {
+            0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x3, 0x78,
+            0x7F, -0x1, -0x1, -0x1, -0x1, -0x1, -0x1, -0x1
+        };
+        // end::noformat
+        BytesReference ref = new BytesArray(array, 0, array.length);
+        assertThat(ref.getLong(0), equalTo(888L));
+        assertThat(ref.getLong(8), equalTo(Long.MAX_VALUE));
+        Exception e = expectThrows(ArrayIndexOutOfBoundsException.class, () -> ref.getLongLE(9));
+        assertThat(e.getMessage(), equalTo("Index 9 out of bounds for length 9"));
+    }
+
+    public void testGetDouble() {
+        // first 8 bytes = 1.2, second 8 bytes = 1.4
+        // tag::noformat
+        byte[] array = new byte[] {
+            0x3F, -0xD, 0x33, 0x33, 0x33, 0x33, 0x33, 0x33,
+            0x3F, -0xA, 0x66, 0x66, 0x66, 0x66, 0x66, 0x66
+        };
+        // end::noformat
+        BytesReference ref = new BytesArray(array, 0, array.length);
+        assertThat(ref.getDouble(0), equalTo(1.2));
+        assertThat(ref.getDouble(8), equalTo(1.4));
+        Exception e = expectThrows(ArrayIndexOutOfBoundsException.class, () -> ref.getDoubleLE(9));
+        assertThat(e.getMessage(), equalTo("Index 9 out of bounds for length 9"));
+    }
 }
diff --git a/server/src/test/java/org/elasticsearch/common/bytes/CompositeBytesReferenceTests.java b/server/src/test/java/org/elasticsearch/common/bytes/CompositeBytesReferenceTests.java
index 99de6ed4711..92939aac97e 100644
--- a/server/src/test/java/org/elasticsearch/common/bytes/CompositeBytesReferenceTests.java
+++ b/server/src/test/java/org/elasticsearch/common/bytes/CompositeBytesReferenceTests.java
@@ -151,6 +151,72 @@ public class CompositeBytesReferenceTests extends AbstractBytesReferenceTestCase
         );
     }
 
+    public void testGetInt() {
+        BytesReference[] refs = new BytesReference[] {
+            new BytesArray(new byte[] { 0x04, 0x03, 0x02, 0x01 }),
+            new BytesArray(new byte[] { 0x00, 0x12, 0x10, 0x12 }) };
+        BytesReference comp = CompositeBytesReference.of(refs);
+        assertThat(comp.getInt(0), equalTo(0x04030201));
+        assertThat(comp.getInt(1), equalTo(0x03020100));
+        assertThat(comp.getInt(2), equalTo(0x02010012));
+        assertThat(comp.getInt(3), equalTo(0x01001210));
+        assertThat(comp.getInt(4), equalTo(0x00121012));
+        // The jvm can optimize throwing ArrayIndexOutOfBoundsException by reusing the same exception,
+        // but these reused exceptions have no message or stack trace. This sometimes happens when running this test case.
+        // We can assert the exception message if -XX:-OmitStackTraceInFastThrow is set in gradle test task.
+        expectThrows(ArrayIndexOutOfBoundsException.class, () -> comp.getInt(5));
+    }
+
+    public void testGetDouble() {
+        // first double = 1.2, second double = 1.4, third double = 1.6
+        // tag::noformat
+        byte[] data = new byte[] {
+            0x3F, -0xD, 0x33, 0x33, 0x33, 0x33, 0x33, 0x33,
+            0x3F, -0xA, 0x66, 0x66, 0x66, 0x66, 0x66, 0x66,
+            0x3F, -0x7, -0x67, -0x67, -0x67, -0x67, -0x67, -0x66};
+        // end::noformat
+
+        List<BytesReference> refs = new ArrayList<>();
+        int bytesPerChunk = randomFrom(4, 16);
+        for (int offset = 0; offset < data.length; offset += bytesPerChunk) {
+            int length = Math.min(bytesPerChunk, data.length - offset);
+            refs.add(new BytesArray(data, offset, length));
+        }
+        BytesReference comp = CompositeBytesReference.of(refs.toArray(BytesReference[]::new));
+        assertThat(comp.getDouble(0), equalTo(1.2));
+        assertThat(comp.getDouble(8), equalTo(1.4));
+        assertThat(comp.getDouble(16), equalTo(1.6));
+        // The jvm can optimize throwing ArrayIndexOutOfBoundsException by reusing the same exception,
+        // but these reused exceptions have no message or stack trace. This sometimes happens when running this test case.
+        // We can assert the exception message if -XX:-OmitStackTraceInFastThrow is set in gradle test task.
+        expectThrows(IndexOutOfBoundsException.class, () -> comp.getDouble(17));
+    }
+
+    public void testGetLong() {
+        // first long = 2, second long = 44, third long = 512
+        // tag::noformat
+        byte[] data = new byte[] {
+            0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x2,
+            0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x2C,
+            0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x2, 0x0};
+        // end::noformat
+
+        byte[] d = new byte[8];
+        ByteUtils.writeLongBE(2, d, 0);
+
+        List<BytesReference> refs = new ArrayList<>();
+        int bytesPerChunk = randomFrom(4, 16);
+        for (int offset = 0; offset < data.length; offset += bytesPerChunk) {
+            int length = Math.min(bytesPerChunk, data.length - offset);
+            refs.add(new BytesArray(data, offset, length));
+        }
+        BytesReference comp = CompositeBytesReference.of(refs.toArray(BytesReference[]::new));
+        assertThat(comp.getLong(0), equalTo(2L));
+        assertThat(comp.getLong(8), equalTo(44L));
+        assertThat(comp.getLong(16), equalTo(512L));
+        expectThrows(IndexOutOfBoundsException.class, () -> comp.getLong(17));
+    }
+
     public void testGetIntLE() {
         BytesReference[] refs = new BytesReference[] {
             new BytesArray(new byte[] { 0x12, 0x10, 0x12, 0x00 }),
diff --git a/settings.gradle b/settings.gradle
index 09aaef7ede1..2e0b6003c4a 100644
--- a/settings.gradle
+++ b/settings.gradle
@@ -61,6 +61,7 @@ List projects = [
   'distribution:archives:darwin-tar',
   'distribution:archives:darwin-aarch64-tar',
   'distribution:archives:linux-aarch64-tar',
+  'distribution:archives:linux-s390x-tar',
   'distribution:archives:linux-tar',
   'distribution:docker',
   'distribution:docker:cloud-docker-export',
@@ -68,14 +69,18 @@ List projects = [
   'distribution:docker:cloud-ess-docker-export',
   'distribution:docker:cloud-ess-docker-aarch64-export',
   'distribution:docker:docker-aarch64-export',
+  'distribution:docker:docker-s390x-export',
   'distribution:docker:docker-export',
   'distribution:docker:ironbank-docker-aarch64-export',
   'distribution:docker:ironbank-docker-export',
   'distribution:docker:ubi-docker-aarch64-export',
+  'distribution:docker:ubi-docker-s390x-export',
   'distribution:docker:ubi-docker-export',
   'distribution:packages:aarch64-deb',
+  'distribution:packages:s390x-deb',
   'distribution:packages:deb',
   'distribution:packages:aarch64-rpm',
+  'distribution:packages:s390x-rpm',
   'distribution:packages:rpm',
   'distribution:bwc:bugfix',
   'distribution:bwc:maintenance',
diff --git a/test/fixtures/krb5kdc-fixture/Dockerfile b/test/fixtures/krb5kdc-fixture/Dockerfile
index e862c7a71f2..5f1ae4da085 100644
--- a/test/fixtures/krb5kdc-fixture/Dockerfile
+++ b/test/fixtures/krb5kdc-fixture/Dockerfile
@@ -1,4 +1,4 @@
-FROM ubuntu:14.04
+FROM ubuntu:20.04
 ADD . /fixture
 RUN echo kerberos.build.elastic.co > /etc/hostname
 RUN bash /fixture/src/main/resources/provision/installkdc.sh
diff --git a/test/fixtures/krb5kdc-fixture/build.gradle b/test/fixtures/krb5kdc-fixture/build.gradle
index 33228661b9a..971fc4d3ab4 100644
--- a/test/fixtures/krb5kdc-fixture/build.gradle
+++ b/test/fixtures/krb5kdc-fixture/build.gradle
@@ -26,7 +26,7 @@ tasks.named("postProcessFixture").configure {
     doLast {
       assert confTemplate.exists()
       String confContents = confTemplate.text
-        .replace("\${MAPPED_PORT}", "${ext."test.fixtures.${service}.udp.88"}")
+        .replace("\${MAPPED_PORT}", ":${ext."test.fixtures.${service}.udp.88"}")
       confFile.text = confContents
     }
   }
diff --git a/test/fixtures/krb5kdc-fixture/src/main/resources/provision/addprinc.sh b/test/fixtures/krb5kdc-fixture/src/main/resources/provision/addprinc.sh
index 78ac6607ab9..2beeefb5e05 100755
--- a/test/fixtures/krb5kdc-fixture/src/main/resources/provision/addprinc.sh
+++ b/test/fixtures/krb5kdc-fixture/src/main/resources/provision/addprinc.sh
@@ -8,8 +8,8 @@
 
 set -e
 
-krb5kdc
-kadmind
+[[ -f /var/run/krb5kdc.pid ]] || krb5kdc -P /var/run/krb5kdc.pid
+[[ -f /var/run/kadmind.pid ]] || kadmind -P /var/run/kadmind.pid
 
 if [[ $# -lt 1 ]]; then
   echo 'Usage: addprinc.sh principalName [password]'
@@ -44,16 +44,16 @@ USER_KTAB=$LOCALSTATEDIR/$USER.keytab
 
 if [ -f $USER_KTAB ] && [ -z "$PASSWD" ]; then
   echo "Principal '${PRINC}@${REALM}' already exists. Re-copying keytab..."
-  sudo cp $USER_KTAB $KEYTAB_DIR/$USER.keytab
+  cp $USER_KTAB $KEYTAB_DIR/$USER.keytab
 else
   if [ -z "$PASSWD" ]; then
     echo "Provisioning '${PRINC}@${REALM}' principal and keytab..."
-    sudo kadmin -p $ADMIN_PRIN -kt $ADMIN_KTAB -q "addprinc -randkey $USER_PRIN"
-    sudo kadmin -p $ADMIN_PRIN -kt $ADMIN_KTAB -q "ktadd -k $USER_KTAB $USER_PRIN"
-    sudo cp $USER_KTAB $KEYTAB_DIR/$USER.keytab
+    kadmin -p $ADMIN_PRIN -kt $ADMIN_KTAB -q "addprinc -randkey $USER_PRIN"
+    kadmin -p $ADMIN_PRIN -kt $ADMIN_KTAB -q "ktadd -k $USER_KTAB $USER_PRIN"
+    cp $USER_KTAB $KEYTAB_DIR/$USER.keytab
   else
     echo "Provisioning '${PRINC}@${REALM}' principal with password..."
-    sudo kadmin -p $ADMIN_PRIN -kt $ADMIN_KTAB -q "addprinc -pw $PASSWD $PRINC"
+    kadmin -p $ADMIN_PRIN -kt $ADMIN_KTAB -q "addprinc -pw $PASSWD $PRINC"
   fi
 fi
 
diff --git a/test/fixtures/krb5kdc-fixture/src/main/resources/provision/installkdc.sh b/test/fixtures/krb5kdc-fixture/src/main/resources/provision/installkdc.sh
index a83147075cf..f28ce3a1de4 100755
--- a/test/fixtures/krb5kdc-fixture/src/main/resources/provision/installkdc.sh
+++ b/test/fixtures/krb5kdc-fixture/src/main/resources/provision/installkdc.sh
@@ -70,6 +70,8 @@ apt-get install -qqy krb5-{admin-server,kdc}
 apt-get install -qqy haveged
 haveged
 
+apt-get install -qqy python3
+
 # Create kerberos database with stash file and garbage password
 kdb5_util create -s -r $REALM_NAME -P zyxwvutsrpqonmlk9876
 
diff --git a/test/fixtures/krb5kdc-fixture/src/main/resources/provision/krb5.conf.template b/test/fixtures/krb5kdc-fixture/src/main/resources/provision/krb5.conf.template
index bec9298e1cc..b0ba5728d13 100644
--- a/test/fixtures/krb5kdc-fixture/src/main/resources/provision/krb5.conf.template
+++ b/test/fixtures/krb5kdc-fixture/src/main/resources/provision/krb5.conf.template
@@ -24,7 +24,7 @@
 [realms]
     ${REALM_NAME} = {
         kdc = 127.0.0.1:88
-        kdc = 127.0.0.1:${MAPPED_PORT}
+        kdc = 127.0.0.1${MAPPED_PORT}
         admin_server = ${KDC_NAME}:749
         default_domain = ${BUILD_ZONE}
     }
diff --git a/test/fixtures/s3-fixture/Dockerfile b/test/fixtures/s3-fixture/Dockerfile
index 97b56ee40a2..03ba92d0667 100644
--- a/test/fixtures/s3-fixture/Dockerfile
+++ b/test/fixtures/s3-fixture/Dockerfile
@@ -1,4 +1,4 @@
-FROM openjdk:17.0.2
+FROM eclipse-temurin:17-jammy
 
 ARG fixtureClass
 ARG port
diff --git a/test/fixtures/s3-fixture/sts/Dockerfile b/test/fixtures/s3-fixture/sts/Dockerfile
index 203ba178028..1c25c954352 100644
--- a/test/fixtures/s3-fixture/sts/Dockerfile
+++ b/test/fixtures/s3-fixture/sts/Dockerfile
@@ -1,4 +1,4 @@
-FROM openjdk:17.0.2
+FROM eclipse-temurin:17-jammy
 
 ARG fixtureClass
 ARG port
diff --git a/test/fixtures/url-fixture/Dockerfile b/test/fixtures/url-fixture/Dockerfile
index d6c1443fa1f..42fa73b77ec 100644
--- a/test/fixtures/url-fixture/Dockerfile
+++ b/test/fixtures/url-fixture/Dockerfile
@@ -1,4 +1,4 @@
-FROM openjdk:17.0.2
+FROM eclipse-temurin:17-jammy
 
 ARG port
 ARG workingDir
diff --git a/x-pack/test/idp-fixture/idp/Dockerfile b/x-pack/test/idp-fixture/idp/Dockerfile
index ea7b6880fb4..2cff52f6f65 100644
--- a/x-pack/test/idp-fixture/idp/Dockerfile
+++ b/x-pack/test/idp-fixture/idp/Dockerfile
@@ -1,6 +1,6 @@
-FROM openjdk:11.0.16-jre AS javabase
+FROM eclipse-temurin:11-jre-jammy AS javabase
 
-ENV JAVA_HOME=/usr/local/openjdk-11
+ENV JAVA_HOME=/opt/java/openjdk
 
 # below is mostly a fork from https://github.com/Unicon/shibboleth-idp-dockerized/blob/master/Dockerfile
 # building entire image to allow for easier upgrades since published image has not been updated for years
@@ -77,8 +77,12 @@ COPY idp/bin/ /usr/local/bin/
 
 # Setting owner ownership and permissions
 RUN useradd jetty -U -s /bin/false \
-    && chown -R root:jetty /opt \
-    && chmod -R 640 /opt \
+    && chown root:jetty /opt \
+    && chmod 640 /opt \
+    && chown -R root:jetty /opt/jetty-distribution* \
+    && chmod -R 640 /opt/jetty-distribution* \
+    && chown -R root:jetty /opt/shibboleth-identity-provider* \
+    && chmod -R 640 /opt/shibboleth-identity-provider* \
     && chown -R root:jetty /opt/shib-jetty-base \
     && chmod -R 640 /opt/shib-jetty-base \
     && chmod -R 750 /opt/shibboleth-idp/bin
diff --git a/x-pack/test/idp-fixture/oidc/Dockerfile b/x-pack/test/idp-fixture/oidc/Dockerfile
index cd18c4c7e30..9ff48abfbb6 100644
--- a/x-pack/test/idp-fixture/oidc/Dockerfile
+++ b/x-pack/test/idp-fixture/oidc/Dockerfile
@@ -1,5 +1,5 @@
 FROM c2id/c2id-server-demo:12.18 AS c2id
-FROM openjdk:11.0.16-jre
+FROM eclipse-temurin:11-jre-jammy
 
 # Using this to launch a fake server on container start; see `setup.sh`
 RUN apt-get update -qqy && apt-get install -qqy python3
