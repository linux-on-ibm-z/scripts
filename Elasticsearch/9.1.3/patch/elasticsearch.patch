diff --git a/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/Jdk.java b/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/Jdk.java
index 1da7d2729bd..67be4586dfd 100644
--- a/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/Jdk.java
+++ b/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/Jdk.java
@@ -25,7 +25,7 @@ import java.util.regex.Pattern;
 
 public class Jdk implements Buildable, Iterable<File> {
 
-    private static final List<String> ALLOWED_ARCHITECTURES = List.of("aarch64", "x64");
+    private static final List<String> ALLOWED_ARCHITECTURES = List.of("aarch64", "s390x", "x64");
     private static final List<String> ALLOWED_VENDORS = List.of("adoptium", "openjdk", "zulu");
     private static final List<String> ALLOWED_PLATFORMS = List.of("darwin", "linux", "windows", "mac");
     private static final Pattern VERSION_PATTERN = Pattern.compile(
diff --git a/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/toolchain/AdoptiumJdkToolchainResolver.java b/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/toolchain/AdoptiumJdkToolchainResolver.java
index ffbb9cc0729..4cf4b3e7f76 100644
--- a/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/toolchain/AdoptiumJdkToolchainResolver.java
+++ b/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/toolchain/AdoptiumJdkToolchainResolver.java
@@ -49,7 +49,8 @@ public abstract class AdoptiumJdkToolchainResolver extends AbstractCustomJavaToo
 
     private AdoptiumVersionRequest toVersionRequest(JavaToolchainRequest request) {
         String platform = toOsString(request.getBuildPlatform().getOperatingSystem(), JvmVendorSpec.ADOPTIUM);
-        String arch = toArchString(request.getBuildPlatform().getArchitecture());
+        //String arch = toArchString(request.getBuildPlatform().getArchitecture());
+        String arch = "s390x";
         JavaLanguageVersion javaLanguageVersion = request.getJavaToolchainSpec().getLanguageVersion().get();
         return new AdoptiumVersionRequest(platform, arch, javaLanguageVersion);
     }
diff --git a/build-tools-internal/version.properties b/build-tools-internal/version.properties
index 87c4fc3cbbc..35fc378e134 100644
--- a/build-tools-internal/version.properties
+++ b/build-tools-internal/version.properties
@@ -3,6 +3,9 @@ lucene            = 10.2.2
 
 bundled_jdk_vendor = openjdk
 bundled_jdk = 24.0.2+12@fdc5d0102fe0414db21410ad5834341f
+bundled_jdk_vendor = adoptium
+bundled_jdk = 21.0.8+9
+
 # optional dependencies
 spatial4j         = 0.7
 jts               = 1.15.0
diff --git a/build-tools/src/main/java/org/elasticsearch/gradle/Architecture.java b/build-tools/src/main/java/org/elasticsearch/gradle/Architecture.java
index c2654f9ae85..ae6390ec315 100644
--- a/build-tools/src/main/java/org/elasticsearch/gradle/Architecture.java
+++ b/build-tools/src/main/java/org/elasticsearch/gradle/Architecture.java
@@ -12,7 +12,8 @@ package org.elasticsearch.gradle;
 public enum Architecture {
 
     X64("x86_64", "linux/amd64", "amd64", "x64"),
-    AARCH64("aarch64", "linux/arm64", "arm64", "aarch64");
+    AARCH64("aarch64", "linux/arm64", "arm64", "aarch64"),
+    S390X("s390x", "linux/s390x", "s390x", "s390x");
 
     public final String classifier;
     public final String dockerPlatform;
@@ -31,6 +32,7 @@ public enum Architecture {
         return switch (architecture) {
             case "amd64", "x86_64" -> X64;
             case "aarch64" -> AARCH64;
+            case "s390x" -> S390X;
             default -> throw new IllegalArgumentException("can not determine architecture from [" + architecture + "]");
         };
     }
diff --git a/distribution/archives/build.gradle b/distribution/archives/build.gradle
index ddfdaa69bb3..df50fd3b2c7 100644
--- a/distribution/archives/build.gradle
+++ b/distribution/archives/build.gradle
@@ -118,6 +118,14 @@ distribution_archives {
     }
   }
 
+  linuxS390xTar {
+    archiveClassifier = 'linux-s390x'
+    content {
+      archiveFiles('tar', 'linux', 's390x', false)
+    }
+  }
+
+
   linuxTar {
     archiveClassifier = 'linux-x86_64'
     content {
diff --git a/distribution/build.gradle b/distribution/build.gradle
index fa6223d30e6..b3a64a024ee 100644
--- a/distribution/build.gradle
+++ b/distribution/build.gradle
@@ -249,7 +249,7 @@ configure(subprojects.findAll { ['archives', 'packages'].contains(it.name) }) {
   // Setup all required JDKs
   project.jdks {
     ['darwin', 'windows', 'linux'].each { platform ->
-      (platform == 'linux' || platform == 'darwin' ? ['x64', 'aarch64'] : ['x64']).each { architecture ->
+      (platform == 'linux' || platform == 'darwin' ? ['x64', 'aarch64', 's390x'] : ['x64']).each { architecture ->
         "bundled_${platform}_${architecture}" {
           it.platform = platform
           it.version = VersionProperties.bundledJdkVersion
@@ -377,7 +377,7 @@ configure(subprojects.findAll { ['archives', 'packages'].contains(it.name) }) {
             it.permissions.unix(0644)
           }
         }
-        List excludePlatforms = ['linux-x86_64', 'linux-aarch64', 'windows-x86_64', 'darwin-x86_64', 'darwin-aarch64']
+        List excludePlatforms = ['linux-x86_64', 'linux-aarch64', 'linux-s390x', 'windows-x86_64', 'darwin-x86_64', 'darwin-aarch64']
         if (os != null) {
           String platform = os + '-' + architecture
           if (architecture == 'x64') {
@@ -633,6 +633,7 @@ subprojects {
  'archives:darwin-tar',
  'archives:darwin-aarch64-tar',
  'archives:linux-aarch64-tar',
+ 'archives:linux-s390x-tar',
  'archives:linux-tar',
  'archives:integ-test-zip',
  'packages:rpm', 'packages:deb',
diff --git a/distribution/docker/build.gradle b/distribution/docker/build.gradle
index 90e0a9383f7..9488efe4e71 100644
--- a/distribution/docker/build.gradle
+++ b/distribution/docker/build.gradle
@@ -89,9 +89,15 @@ configurations {
       attribute(ArtifactTypeDefinition.ARTIFACT_TYPE_ATTRIBUTE, ArtifactTypeDefinition.DIRECTORY_TYPE)
     }
   }
+  s390xDockerSource {
+    attributes {
+      attribute(ArtifactTypeDefinition.ARTIFACT_TYPE_ATTRIBUTE, ArtifactTypeDefinition.DIRECTORY_TYPE)
+    }
+  }
   // Iron bank images require a tarball
   aarch64DockerSourceTar
   dockerSourceTar
+  s390xDockerSourceTar
 
   log4jConfig
   tini
@@ -100,20 +106,26 @@ configurations {
   filebeat_fips_aarch64
   filebeat_x86_64
   filebeat_fips_x86_64
+  filebeat_s390x
+  filebeat_fips_s390x
   metricbeat_aarch64
   metricbeat_fips_aarch64
   metricbeat_x86_64
   metricbeat_fips_x86_64
+  metricbeat_s390x
+  metricbeat_fips_s390x
   fips
 }
 
-String tiniArch = Architecture.current() == Architecture.AARCH64 ? 'arm64' : 'amd64'
+String tiniArch = Architecture.current() == Architecture.AARCH64 ? 'arm64' : Architecture.current() == Architecture.S390X ? 's390x' : 'amd64'
 
 dependencies {
   aarch64DockerSource project(":distribution:archives:linux-aarch64-tar")
   aarch64DockerSourceTar project(path: ":distribution:archives:linux-aarch64-tar", configuration: "default")
   dockerSource project(":distribution:archives:linux-tar")
   dockerSourceTar project(path: ":distribution:archives:linux-tar", configuration: "default")
+  s390xDockerSource project(":distribution:archives:linux-s390x-tar")
+  s390xDockerSourceTar project(path: ":distribution:archives:linux-s390x-tar", configuration:"default")
   log4jConfig project(path: ":distribution", configuration: 'log4jConfig')
   tini "krallin:tini:0.19.0:${tiniArch}"
   allPlugins project(path: ':plugins', configuration: 'allPlugins')
@@ -122,12 +134,15 @@ dependencies {
   filebeat_x86_64 "beats:filebeat:${VersionProperties.elasticsearch}:linux-x86_64@tar.gz"
   filebeat_fips_aarch64 "beats:filebeat-fips:${VersionProperties.elasticsearch}:linux-arm64@tar.gz"
   filebeat_fips_x86_64 "beats:filebeat-fips:${VersionProperties.elasticsearch}:linux-x86_64@tar.gz"
+  filebeat_fips_s390x "beats:filebeat-fips:${VersionProperties.elasticsearch}:linux-s390x@tar.gz"
 
   metricbeat_aarch64 "beats:metricbeat:${VersionProperties.elasticsearch}:linux-arm64@tar.gz"
   metricbeat_x86_64 "beats:metricbeat:${VersionProperties.elasticsearch}:linux-x86_64@tar.gz"
+  metricbeat_s390x "beats:metricbeat:${VersionProperties.elasticsearch}:linux-s390x@tar.gz"
 
   metricbeat_fips_aarch64 "beats:metricbeat-fips:${VersionProperties.elasticsearch}:linux-arm64@tar.gz"
   metricbeat_fips_x86_64 "beats:metricbeat-fips:${VersionProperties.elasticsearch}:linux-x86_64@tar.gz"
+  metricbeat_fips_s390x "beats:metricbeat-fips:${VersionProperties.elasticsearch}:linux-s390x@tar.gz"
 
   fips "org.bouncycastle:bc-fips:1.0.2.5"
   fips "org.bouncycastle:bctls-fips:1.0.19"
@@ -176,7 +191,7 @@ private static String toCamel(String input) {
 
 private static String taskName(String prefix, Architecture architecture, DockerBase base, String suffix) {
   return prefix +
-    (architecture == Architecture.AARCH64 ? 'Aarch64' : '') +
+    (architecture == Architecture.AARCH64 ? 'Aarch64' : architecture == Architecture.S390X ? 's390x' : '') +
     (base == DockerBase.DEFAULT ? "" : toCamel(base.name())) +
     suffix
 }
@@ -230,7 +245,7 @@ tasks.register("copyNodeKeyMaterial", Sync) {
 
 elasticsearch_distributions {
   Architecture.values().each { eachArchitecture ->
-    "docker_${eachArchitecture == Architecture.AARCH64 ? '_aarch64' : ''}" {
+    "docker_${eachArchitecture == Architecture.AARCH64 ? '_aarch64' : eachArchitecture == Architecture.S390X ? '_s390x' : ''}" {
       architecture = eachArchitecture
       type = InternalElasticsearchDistributionTypes.DOCKER
       version = VersionProperties.getElasticsearch()
@@ -300,7 +315,7 @@ def exportDockerContexts = tasks.register("exportDockerContexts")
 
 void addBuildDockerContextTask(Architecture architecture, DockerBase base, String taskSuffix = 'DockerContext', String classifier = "docker-build-context") {
   String configDirectory = base == DockerBase.IRON_BANK ? 'scripts' : 'config'
-  String arch = architecture == Architecture.AARCH64 ? '-aarch64' : ''
+  String arch = architecture == Architecture.AARCH64 ? '-aarch64' : architecture == Architecture.S390X ? '-s390x' : ''
 
   final TaskProvider<Tar> buildDockerContextTask =
     tasks.register(taskName('build', architecture, base, taskSuffix), Tar) {
@@ -367,7 +382,7 @@ void addTransformDockerContextTask(Architecture architecture, DockerBase base) {
     TaskProvider<Tar> buildContextTask = tasks.named(taskName("build", architecture, base, "DockerContext"))
     dependsOn(buildContextTask)
 
-    String arch = architecture == Architecture.AARCH64 ? '-aarch64' : ''
+    String arch = architecture == Architecture.AARCH64 ? '-aarch64' : architecture == Architecture.S390X ? '-s390x' : ''
     String archiveName = "elasticsearch${base.suffix}-${VersionProperties.elasticsearch}-docker-build-context${arch}"
     String distributionFolderName = "elasticsearch-${VersionProperties.elasticsearch}"
 
@@ -399,12 +414,12 @@ void addTransformDockerContextTask(Architecture architecture, DockerBase base) {
 
     // Since we replaced the remote URL in the Dockerfile, copy in the required file
     if (base == DockerBase.IRON_BANK) {
-      from(architecture == Architecture.AARCH64 ? configurations.aarch64DockerSourceTar : configurations.dockerSourceTar)
+      from(architecture == Architecture.AARCH64 ? configurations.aarch64DockerSourceTar : architecture == Architecture.S390X ? configurations.s390xDockerSourceTar : configurations.dockerSourceTar)
       from(configurations.tini) {
         rename { _ -> 'tini' }
       }
     } else {
-      from(architecture == Architecture.AARCH64 ? configurations.aarch64DockerSource : configurations.dockerSource)
+      from(architecture == Architecture.AARCH64 ? configurations.aarch64DockerSource : architecture == Architecture.S390X ? configurations.s390xDockerSource : configurations.dockerSource)
     }
 
     expansions(architecture, base).findAll { it.key != 'build_date' }.each { k, v ->
@@ -506,7 +521,7 @@ void addBuildDockerImageTask(Architecture architecture, DockerBase base) {
 
 void addBuildCloudDockerImageTasks(Architecture architecture) {
   DockerBase dockerBase = DockerBase.CLOUD_ESS
-  String arch = architecture == Architecture.AARCH64 ? '-aarch64' : ''
+  String arch = architecture == Architecture.AARCH64 ? '-aarch64' : architecture == Architecture.S390X ? '-s390x' : ''
   String contextDir = "${project.buildDir}/docker-context/elasticsearch${dockerBase.suffix}-${VersionProperties.elasticsearch}-docker-build-context${arch}"
 
   final TaskProvider<Sync> buildContextTask =
@@ -607,7 +622,7 @@ subprojects { Project subProject ->
   if (subProject.name.endsWith('-export')) {
     apply plugin: 'distribution'
 
-    final Architecture architecture = subProject.name.contains('aarch64-') ? Architecture.AARCH64 : Architecture.X64
+    final Architecture architecture = subProject.name.contains('aarch64-') ? Architecture.AARCH64 : subProject.name.contains('s390x-') ? Architecture.S390X : Architecture.X64
     DockerBase base = DockerBase.DEFAULT
     if (subProject.name.contains('ironbank-')) {
       base = DockerBase.IRON_BANK
@@ -619,7 +634,7 @@ subprojects { Project subProject ->
       base = DockerBase.CLOUD_ESS_FIPS
     }
 
-    final String arch = architecture == Architecture.AARCH64 ? '-aarch64' : ''
+    final String arch = architecture == Architecture.AARCH64 ? '-aarch64' : architecture == Architecture.S390X ? '-s390x' : ''
     final String extension =
       (base == DockerBase.IRON_BANK ? 'ironbank.tar' :
         (base == DockerBase.CLOUD_ESS ? 'cloud-ess.tar' :
diff --git a/distribution/docker/src/docker/Dockerfile b/distribution/docker/src/docker/Dockerfile
index 4cb4e9fe008..8000db358b6 100644
--- a/distribution/docker/src/docker/Dockerfile
+++ b/distribution/docker/src/docker/Dockerfile
@@ -44,7 +44,7 @@ RUN chmod 0555 /bin/tini
 <% if (docker_base == "wolfi") { %>
 RUN <%= retry.loop(package_manager, "export DEBIAN_FRONTEND=noninteractive && ${package_manager} update && ${package_manager} update && ${package_manager} add --no-cache curl") %>
 <% } else { %>
-RUN <%= retry.loop(package_manager, "${package_manager} install -y findutils tar gzip") %>
+RUN <%= retry.loop(package_manager, "${package_manager} install -y findutils tar gzip locales make gcc") %>
 <% } %>
 
 <% if (docker_base != 'wolfi') { %>
@@ -60,6 +60,7 @@ RUN <%= retry.loop(package_manager, "${package_manager} install -y findutils tar
         case "\$(arch)" in \\
             aarch64) tini_bin='tini-arm64' ;; \\
             x86_64)  tini_bin='tini-amd64' ;; \\
+            s390x)   tini_bin='tini-s390x' ;; \\
             *) echo >&2 ; echo >&2 "Unsupported architecture \$(arch)" ; echo >&2 ; exit 1 ;; \\
         esac ; \\
         curl --retry 10 -S -L -O https://github.com/krallin/tini/releases/download/v0.19.0/\${tini_bin} ; \\
@@ -79,7 +80,7 @@ WORKDIR /usr/share/elasticsearch
   // Iron Bank always copies the local artifact. It uses `arch` from the
   // template context variables.
 %>
-COPY elasticsearch-${version}-linux-${arch}.tar.gz /tmp/elasticsearch.tar.gz
+COPY ../../../archives/linux-s390x-tar/build/distribution/elasticsearch-${version}-linux-${arch}.tar.gz /tmp/elasticsearch.tar.gz
 <% } else {
   // Fetch the appropriate Elasticsearch distribution for this architecture.
   // Keep this command on one line - it is replaced with a `COPY` during local builds.
@@ -111,10 +112,76 @@ RUN sed -i -e 's/ES_DISTRIBUTION_TYPE=tar/ES_DISTRIBUTION_TYPE=docker/' bin/elas
     mv config/log4j2.docker.properties config/log4j2.properties && \\
     find . -type d -exec chmod 0555 {} + && \\
     find . -type f -exec chmod 0444 {} + && \\
-    chmod 0555 bin/* jdk/bin/* jdk/lib/jspawnhelper modules/x-pack-ml/platform/linux-*/bin/* && \\
+    chmod 0555 bin/* jdk/bin/* jdk/lib/jspawnhelper && \\
     chmod 0775 bin config config/jvm.options.d data logs plugins && \\
     find config -type f -exec chmod 0664 {} +
 
+# Rebuild jansi native lib so that it uses the image's glibc
+RUN mkdir jansi_tmp && cd jansi_tmp && \\
+   curl --retry 10 -S -L -O https://github.com/fusesource/jansi/archive/refs/tags/jansi-2.4.0.tar.gz && \\
+   tar -zxf jansi-2.4.0.tar.gz --strip-components=1 && \\
+   make clean-native native OS_NAME=Linux OS_ARCH=s390x && \\
+   curl --retry 10 -S -L -O https://repo1.maven.org/maven2/org/fusesource/jansi/jansi/2.4.0/jansi-2.4.0.jar && \\
+   mkdir -p org/fusesource/jansi/internal/native/Linux/s390x && \\
+   cp target/native-Linux-s390x/libjansi.so org/fusesource/jansi/internal/native/Linux/s390x/ && \\
+   ../jdk/bin/jar uf ../lib/tools/ansi-console/jansi-2.4.0.jar org/fusesource/jansi/internal/native/Linux/s390x/libjansi.so && \\
+   cd ../ && rm -rf jansi_tmp
+
+# Rebuild zstd native lib so that it uses the image's glibc
+RUN mkdir zstd_tmp && cd zstd_tmp && \\
+    curl --retry 10 -S -L -O https://github.com/facebook/zstd/archive/refs/tags/v1.5.5.tar.gz && \\
+    tar -xzvf v1.5.5.tar.gz && \\
+    cd zstd-1.5.5 && \\
+    make -j\$(nproc) lib && \\
+    make DESTDIR=\$(pwd)/_build install && \\
+    cp _build/usr/local/lib/libzstd.so ../../lib/platform/linux-s390x/ && \\
+    cd ../../ && rm -rf zstd_tmp/
+
+<% if (docker_base == "cloud_ess_fips") { %>
+
+# Add plugins infrastructure
+RUN mkdir -p /opt/plugins/archive
+RUN chmod -R 0555 /opt/plugins
+
+RUN mkdir -p /fips/libs
+COPY fips/libs/*.jar /fips/libs/
+
+COPY filebeat-${version}.tar.gz metricbeat-${version}.tar.gz /tmp/
+RUN set -eux ; \\
+    for beat in filebeat metricbeat ; do \\
+      if [ ! -s /tmp/\$beat-${version}.tar.gz ]; then \\
+        echo "/tmp/\$beat-${version}.tar.gz is empty - cannot uncompress" 2>&1 ; \\
+        exit 1 ; \\
+      fi ; \\
+      if ! tar tf /tmp/\$beat-${version}.tar.gz >/dev/null; then \\
+        echo "/tmp/\$beat-${version}.tar.gz is corrupt - cannot uncompress" 2>&1 ; \\
+        exit 1 ; \\
+      fi ; \\
+      mkdir -p /opt/\$beat ; \\
+      tar xf /tmp/\$beat-${version}.tar.gz -C /opt/\$beat --strip-components=1 ; \\
+    done
+
+COPY plugins/*.zip /opt/plugins/archive/
+
+RUN chown 1000:1000 /opt/plugins/archive/*
+RUN chmod 0444 /opt/plugins/archive/*
+
+COPY fips/resources/fips_java.security /usr/share/elasticsearch/config/fips_java.security
+COPY fips/resources/fips_java.policy /usr/share/elasticsearch/config/fips_java.policy
+
+WORKDIR /usr/share/elasticsearch/config
+
+## Add fips specific JVM options
+RUN cat <<EOF > /usr/share/elasticsearch/config/jvm.options.d/fips.options
+-Djavax.net.ssl.keyStoreType=BCFKS
+-Dorg.bouncycastle.fips.approved_only=true
+-Djava.security.properties=config/fips_java.security
+-Djava.security.policy=config/fips_java.policy
+EOF
+
+<% } %>
+
+
 ################################################################################
 # Build stage 2 (the actual Elasticsearch image):
 #
@@ -179,6 +246,7 @@ ENV ELASTIC_CONTAINER=true
 WORKDIR /usr/share/elasticsearch
 
 COPY --from=builder --chown=0:0 /usr/share/elasticsearch /usr/share/elasticsearch
+
 <% if (docker_base != "wolfi") { %>
 COPY --from=builder --chown=0:0 /bin/tini /bin/tini
 <% } %>
diff --git a/distribution/docker/src/docker/config/elasticsearch.yml b/distribution/docker/src/docker/config/elasticsearch.yml
index 50b154702b9..69d740350b7 100644
--- a/distribution/docker/src/docker/config/elasticsearch.yml
+++ b/distribution/docker/src/docker/config/elasticsearch.yml
@@ -1,2 +1,3 @@
 cluster.name: "docker-cluster"
 network.host: 0.0.0.0
+xpack.ml.enabled: false
diff --git a/distribution/docker/src/docker/dockerfiles/default/Dockerfile b/distribution/docker/src/docker/dockerfiles/default/Dockerfile
index 0e22e56307c..551e0ec4b83 100644
--- a/distribution/docker/src/docker/dockerfiles/default/Dockerfile
+++ b/distribution/docker/src/docker/dockerfiles/default/Dockerfile
@@ -21,7 +21,7 @@
 
 FROM ${base_image} AS builder
 
-RUN microdnf install -y findutils tar gzip
+RUN microdnf install -y findutils tar gzip make gcc
 
 # `tini` is a tiny but valid init for containers. This is used to cleanly
 # control how ES and any child processes are shut down.
@@ -34,6 +34,7 @@ RUN set -eux; \\
     case "\$arch" in \\
         aarch64) tini_bin='tini-arm64'; tini_sum='07952557df20bfd2a95f9bef198b445e006171969499a1d361bd9e6f8e5e0e81' ;; \\
         x86_64)  tini_bin='tini-amd64'; tini_sum='93dcc18adc78c65a028a84799ecf8ad40c936fdfc5f2a57b1acda5a8117fa82c' ;; \\
+        s390x)   tini_bin='tini-s390x'; tini_sum='931b70a182af879ca249ae9de87ef68423121b38d235c78997fafc680ceab32d' ;; \\
         *) echo >&2 "Unsupported architecture \$arch"; exit 1 ;; \\
     esac ; \\
     curl -f --retry 10 -S -L -o /tmp/tini https://github.com/krallin/tini/releases/download/v0.19.0/\${tini_bin}; \\
@@ -55,7 +56,7 @@ RUN tar -zxf /tmp/elasticsearch.tar.gz --strip-components=1 && \\
 # Reset permissions on all files
     find . -type f -exec chmod 0444 {} + && \\
 # Make CLI tools executable
-    chmod 0555 bin/* jdk/bin/* jdk/lib/jspawnhelper modules/x-pack-ml/platform/linux-*/bin/* && \\
+    chmod 0555 bin/* jdk/bin/* jdk/lib/jspawnhelper && \\
 # Make some directories writable. `bin` must be writable because
 # plugins can install their own CLI utilities.
     chmod 0775 bin config config/jvm.options.d data logs plugins && \\
@@ -71,6 +72,26 @@ RUN tar -zxf /tmp/elasticsearch.tar.gz --strip-components=1 && \\
 # The distribution includes a `config` directory, no need to create it
 COPY --chmod=664 config/elasticsearch.yml config/log4j2.properties config/
 
+# Rebuild jansi native lib so that it uses the image's glibc
+RUN mkdir jansi_tmp && cd jansi_tmp && \\
+   curl --retry 10 -S -L -O https://github.com/fusesource/jansi/archive/refs/tags/jansi-2.4.0.tar.gz && \\
+   tar -zxf jansi-2.4.0.tar.gz --strip-components=1 && \\
+   make clean-native native OS_NAME=Linux OS_ARCH=s390x && \\
+   curl --retry 10 -S -L -O https://repo1.maven.org/maven2/org/fusesource/jansi/jansi/2.4.0/jansi-2.4.0.jar && \\
+   mkdir -p org/fusesource/jansi/internal/native/Linux/s390x && \\
+   cp target/native-Linux-s390x/libjansi.so org/fusesource/jansi/internal/native/Linux/s390x/ && \\
+   ../jdk/bin/jar uf ../lib/tools/ansi-console/jansi-2.4.0.jar org/fusesource/jansi/internal/native/Linux/s390x/libjansi.so && \\
+   cd ../ && rm -rf jansi_tmp
+
+# Rebuild zstd native lib so that it uses the image's glibc
+RUN mkdir zstd_tmp && cd zstd_tmp && \\
+    curl --retry 10 -S -L -O https://github.com/facebook/zstd/archive/refs/tags/v1.5.5.tar.gz && \\
+    tar -xzvf v1.5.5.tar.gz && \\
+    cd zstd-1.5.5 && \\
+    make -j\$(nproc) lib && \\
+    make DESTDIR=\$(pwd)/_build install && \\
+    cp _build/usr/local/lib/libzstd.so ../../lib/platform/linux-s390x/ && \\
+    cd ../../ && rm -rf zstd_tmp/
 
 ################################################################################
 # Build stage 2 (the actual Elasticsearch image):
diff --git a/distribution/packages/build.gradle b/distribution/packages/build.gradle
index 570bccc394a..645bc77f1c2 100644
--- a/distribution/packages/build.gradle
+++ b/distribution/packages/build.gradle
@@ -91,6 +91,8 @@ def commonPackageConfig(String type, String architecture) {
     if (type == 'deb') {
       if (architecture == 'x64') {
         arch = 'amd64'
+      } else if (architecture == 's390x') {
+        arch = 's390x'
       } else {
         assert architecture == 'aarch64': architecture
         arch = 'arm64'
@@ -99,13 +101,15 @@ def commonPackageConfig(String type, String architecture) {
       assert type == 'rpm': type
       if (architecture == 'x64') {
         arch = 'X86_64'
+      } else if (architecture == 's390x') {
+        arch = 's390x'
       } else {
         assert architecture == 'aarch64': architecture
         arch = 'aarch64'
       }
     }
     // Follow elasticsearch's file naming convention
-    String prefix = "${architecture == 'aarch64' ? 'aarch64-' : ''}${type}"
+    String prefix = "${architecture == 'aarch64' ? 'aarch64-' : 's390x' ? 's390x-' : ''}${type}"
     destinationDirectory = file("${prefix}/build/distributions")
     archiveFileName.value(project.provider({ "${packageName}-${project.version}-${archString}.${type}" }))
     String packagingFiles = "build/packaging/${type}"
@@ -350,6 +354,10 @@ tasks.register('buildAarch64Deb', Deb) {
   configure(commonDebConfig('aarch64'))
 }
 
+tasks.register('buildS390xDeb', Deb) {
+  configure(commonDebConfig('s390x'))
+}
+
 tasks.register('buildDeb', Deb) {
   configure(commonDebConfig('x64'))
 }
@@ -383,6 +391,10 @@ tasks.register('buildAarch64Rpm', Rpm) {
   configure(commonRpmConfig('aarch64'))
 }
 
+tasks.register('buildS390xRpm', Rpm) {
+  configure(commonRpmConfig('s390x'))
+}
+
 tasks.register('buildRpm', Rpm) {
   configure(commonRpmConfig('x64'))
 }
diff --git a/gradle/verification-metadata.xml b/gradle/verification-metadata.xml
index e4adec09f17..3947cbb7339 100644
--- a/gradle/verification-metadata.xml
+++ b/gradle/verification-metadata.xml
@@ -39,6 +39,11 @@
             <sha256 value="d083479ca927dce2f586f779373d895e8bf668c632505740279390384edf03fa" origin="Generated by Gradle"/>
          </artifact>
       </component>
+      <component group="adoptium_21" name="linux" version="21.0.8">
+         <artifact name="linux-21.0.8-s390x.tar.gz">
+            <sha256 value="a84e3cbf8bb5f8a313e06b790c7bc388687ba00262e981f5e33432ebd4d34356" origin="Generated by Gradle"/>
+         </artifact>
+      </component>
       <component group="adoptium_8" name="linux" version="8u302">
          <artifact name="linux-8u302-aarch64.tar.gz">
             <sha256 value="f287cdc2a688c2df247ea0d8bfe2863645b73848e4e5c35b02a8a3d2d6b69551" origin="Generated by Gradle"/>
diff --git a/libs/native/libraries/build.gradle b/libs/native/libraries/build.gradle
index 58562ddcd68..3e1b4866676 100644
--- a/libs/native/libraries/build.gradle
+++ b/libs/native/libraries/build.gradle
@@ -24,11 +24,8 @@ var vecVersion = "1.0.11"
 repositories {
   exclusiveContent {
     forRepository {
-      maven {
-        url = "https://artifactory.elastic.dev/artifactory/elasticsearch-native"
-        metadataSources {
-          artifact()
-        }
+      flatDir {
+        dirs '%S390X_ZSTD_DEP_DIR%'
       }
     }
     filter {
@@ -47,12 +44,13 @@ dependencies {
     transformSpec.getFrom().attribute(ArtifactTypeDefinition.ARTIFACT_TYPE_ATTRIBUTE, ArtifactTypeDefinition.ZIP_TYPE);
     transformSpec.getTo().attribute(ArtifactTypeDefinition.ARTIFACT_TYPE_ATTRIBUTE, ArtifactTypeDefinition.DIRECTORY_TYPE);
   });
-  libs "org.elasticsearch:zstd:${zstdVersion}:darwin-aarch64"
-  libs "org.elasticsearch:zstd:${zstdVersion}:darwin-x86-64"
-  libs "org.elasticsearch:zstd:${zstdVersion}:linux-aarch64"
-  libs "org.elasticsearch:zstd:${zstdVersion}:linux-x86-64"
-  libs "org.elasticsearch:zstd:${zstdVersion}:windows-x86-64"
-  libs "org.elasticsearch:vec:${vecVersion}@zip" // temporarily comment this out, if testing a locally built native lib
+  // libs "org.elasticsearch:zstd:${zstdVersion}:darwin-aarch64"
+  // libs "org.elasticsearch:zstd:${zstdVersion}:darwin-x86-64"
+  // libs "org.elasticsearch:zstd:${zstdVersion}:linux-aarch64"
+  // libs "org.elasticsearch:zstd:${zstdVersion}:linux-x86-64"
+  // libs "org.elasticsearch:zstd:${zstdVersion}:windows-x86-64"
+  // libs "org.elasticsearch:vec:${vecVersion}@zip" // temporarily comment this out, if testing a locally built native lib
+  libs "org.elasticsearch:zstd:${zstdVersion}:linux-s390x"
 }
 
 def extractLibs = tasks.register('extractLibs', Copy) {
diff --git a/libs/native/src/main/java/org/elasticsearch/nativeaccess/LinuxNativeAccess.java b/libs/native/src/main/java/org/elasticsearch/nativeaccess/LinuxNativeAccess.java
index b174c0c5317..f3bc238dd35 100644
--- a/libs/native/src/main/java/org/elasticsearch/nativeaccess/LinuxNativeAccess.java
+++ b/libs/native/src/main/java/org/elasticsearch/nativeaccess/LinuxNativeAccess.java
@@ -83,7 +83,9 @@ class LinuxNativeAccess extends PosixNativeAccess {
             "amd64",
             new Arch(0xC000003E, 0x3FFFFFFF, 57, 58, 59, 322, 317),
             "aarch64",
-            new Arch(0xC00000B7, 0xFFFFFFFF, 1079, 1071, 221, 281, 277)
+            new Arch(0xC00000B7, 0xFFFFFFFF, 1079, 1071, 221, 281, 277),
+            "s390x",
+            new Arch(0x80000016, 0x3FFFFFFF, 2, 190, 11, 354, 348)
         );
     }
 
@@ -91,7 +93,7 @@ class LinuxNativeAccess extends PosixNativeAccess {
     private final Systemd systemd;
 
     LinuxNativeAccess(NativeLibraryProvider libraryProvider) {
-        super("Linux", libraryProvider, new PosixConstants(-1L, 9, 1, 8, 64, 144, 48, 64));
+        super("Linux", libraryProvider, new PosixConstants(-1L, 9, 1, 8, 64, 144, 48, (System.getProperty("os.arch").equals("s390x") ? 112 : 644)));
         this.linuxLibc = libraryProvider.getLibrary(LinuxCLibrary.class);
         String socketPath = System.getenv("NOTIFY_SOCKET");
         if (socketPath == null) {
diff --git a/libs/native/src/main/java/org/elasticsearch/nativeaccess/lib/LoaderHelper.java b/libs/native/src/main/java/org/elasticsearch/nativeaccess/lib/LoaderHelper.java
index 98887381e5d..d18935669cc 100644
--- a/libs/native/src/main/java/org/elasticsearch/nativeaccess/lib/LoaderHelper.java
+++ b/libs/native/src/main/java/org/elasticsearch/nativeaccess/lib/LoaderHelper.java
@@ -46,6 +46,8 @@ public class LoaderHelper {
             arch = "x64";
         } else if (archname.equals("aarch64")) {
             arch = archname;
+        } else if (archname.equals("s390x")) {
+            arch = archname;
         } else {
             arch = "unsupported_arch[" + archname + "]";
         }
diff --git a/server/src/main/java/org/elasticsearch/bootstrap/BootstrapChecks.java b/server/src/main/java/org/elasticsearch/bootstrap/BootstrapChecks.java
index daaf1dc2d07..a941a82d7b5 100644
--- a/server/src/main/java/org/elasticsearch/bootstrap/BootstrapChecks.java
+++ b/server/src/main/java/org/elasticsearch/bootstrap/BootstrapChecks.java
@@ -223,7 +223,6 @@ final class BootstrapChecks {
         checks.add(new OnOutOfMemoryErrorCheck());
         checks.add(new EarlyAccessCheck());
         checks.add(new DiscoveryConfiguredCheck());
-        checks.add(new ByteOrderCheck());
         return Collections.unmodifiableList(checks);
     }
 
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/AbstractBytesReference.java b/server/src/main/java/org/elasticsearch/common/bytes/AbstractBytesReference.java
index 1020106a64a..3e992c7a18e 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/AbstractBytesReference.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/AbstractBytesReference.java
@@ -38,6 +38,18 @@ public abstract class AbstractBytesReference implements BytesReference {
         return (get(index) & 0xFF) << 24 | (get(index + 1) & 0xFF) << 16 | (get(index + 2) & 0xFF) << 8 | get(index + 3) & 0xFF;
     }
 
+    @Override
+    public long getLong(int index) {
+        return (long) (get(index) & 0xFF) << 56 | (long) (get(index + 1) & 0xFF) << 48 | (long) (get(index + 2) & 0xFF) << 40
+            | (long) (get(index + 3) & 0xFF) << 32 | (long) (get(index + 4) & 0xFF) << 24 | (get(index + 5) & 0xFF) << 16 | (get(index + 6)
+            & 0xFF) << 8 | get(index + 7) & 0xFF;
+    }
+
+    @Override
+    public double getDouble(int index) {
+        return Double.longBitsToDouble(getLong(index));
+    }
+
     @Override
     public int getIntLE(int index) {
         return (get(index + 3) & 0xFF) << 24 | (get(index + 2) & 0xFF) << 16 | (get(index + 1) & 0xFF) << 8 | get(index) & 0xFF;
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/BytesArray.java b/server/src/main/java/org/elasticsearch/common/bytes/BytesArray.java
index 811c3c1c987..68806973da7 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/BytesArray.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/BytesArray.java
@@ -225,6 +225,21 @@ public final class BytesArray extends AbstractBytesReference {
         os.write(bytes, offset, length);
     }
 
+    @Override
+    public int getInt(int index) {
+        return ByteUtils.readIntBE(bytes, offset + index);
+    }
+
+    @Override
+    public long getLong(int index) {
+        return ByteUtils.readLongBE(bytes, offset + index);
+    }
+
+    @Override
+    public double getDouble(int index) {
+        return ByteUtils.readDoubleBE(bytes, offset + index);
+    }
+
     @Override
     public int getIntLE(int index) {
         return ByteUtils.readIntLE(bytes, offset + index);
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java b/server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java
index 26df48fc9ec..e4274e76a63 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/BytesReference.java
@@ -125,6 +125,16 @@ public interface BytesReference extends Comparable<BytesReference>, ToXContentFr
      */
     int getInt(int index);
 
+    /**
+     * Returns the long read from the 8 bytes (BE) starting at the given index.
+     */
+    long getLong(int index);
+
+    /**
+     * Returns the double read from the 8 bytes (BE) starting at the given index.
+     */
+    double getDouble(int index);
+
     /**
      * Returns the integer read from the 4 bytes (LE) starting at the given index.
      */
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java b/server/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java
index 537082fedd6..6731d92cc52 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java
@@ -239,6 +239,42 @@ public final class CompositeBytesReference extends AbstractBytesReference {
         return ramBytesUsed;
     }
 
+    @Override
+    public int getInt(int index) {
+        int i = getOffsetIndex(index);
+        int idx = index - offsets[i];
+        int end = idx + 4;
+        BytesReference wholeIntLivesHere = references[i];
+        if (end <= wholeIntLivesHere.length()) {
+            return wholeIntLivesHere.getInt(idx);
+        }
+        return super.getInt(index);
+    }
+
+    @Override
+    public long getLong(int index) {
+        int i = getOffsetIndex(index);
+        int idx = index - offsets[i];
+        int end = idx + 8;
+        BytesReference wholeLongsLivesHere = references[i];
+        if (end <= wholeLongsLivesHere.length()) {
+            return wholeLongsLivesHere.getLong(idx);
+        }
+        return super.getLong(index);
+    }
+
+    @Override
+    public double getDouble(int index) {
+        int i = getOffsetIndex(index);
+        int idx = index - offsets[i];
+        int end = idx + 8;
+        BytesReference wholeDoublesLivesHere = references[i];
+        if (end <= wholeDoublesLivesHere.length()) {
+            return wholeDoublesLivesHere.getDouble(idx);
+        }
+        return super.getDouble(index);
+    }
+
     @Override
     public int getIntLE(int index) {
         int i = getOffsetIndex(index);
diff --git a/server/src/main/java/org/elasticsearch/common/bytes/ReleasableBytesReference.java b/server/src/main/java/org/elasticsearch/common/bytes/ReleasableBytesReference.java
index ff8e68d4628..95ae579a915 100644
--- a/server/src/main/java/org/elasticsearch/common/bytes/ReleasableBytesReference.java
+++ b/server/src/main/java/org/elasticsearch/common/bytes/ReleasableBytesReference.java
@@ -119,6 +119,18 @@ public final class ReleasableBytesReference implements RefCounted, Releasable, B
         return delegate.getInt(index);
     }
 
+    @Override
+    public long getLong(int index) {
+        assert hasReferences();
+        return delegate.getLong(index);
+    }
+
+    @Override
+    public double getDouble(int index) {
+        assert hasReferences();
+        return delegate.getDouble(index);
+    }
+
     @Override
     public int getIntLE(int index) {
         assert hasReferences();
diff --git a/server/src/main/java/org/elasticsearch/common/util/ByteUtils.java b/server/src/main/java/org/elasticsearch/common/util/ByteUtils.java
index 72b3e65ec50..1a009143932 100644
--- a/server/src/main/java/org/elasticsearch/common/util/ByteUtils.java
+++ b/server/src/main/java/org/elasticsearch/common/util/ByteUtils.java
@@ -82,6 +82,16 @@ public enum ByteUtils {
         return (long) BIG_ENDIAN_LONG.get(arr, offset);
     }
 
+    /**
+     * Converts a byte array written in little big format to a double.
+     *
+     * @param arr The byte array to read from in big endian layout
+     * @param offset The offset where in the array to read from
+     */
+    public static double readDoubleBE(byte[] arr, int offset) {
+        return Double.longBitsToDouble(readLongBE(arr, offset));
+    }
+
     /**
      * Converts an int to a byte array in little endian format.
      *
diff --git a/server/src/main/java/org/elasticsearch/common/util/ReleasableDoubleArray.java b/server/src/main/java/org/elasticsearch/common/util/ReleasableDoubleArray.java
index ccfb6ee14e8..231b0043a88 100644
--- a/server/src/main/java/org/elasticsearch/common/util/ReleasableDoubleArray.java
+++ b/server/src/main/java/org/elasticsearch/common/util/ReleasableDoubleArray.java
@@ -41,7 +41,7 @@ class ReleasableDoubleArray implements DoubleArray {
             // We can't serialize messages longer than 2gb anyway
             throw new ArrayIndexOutOfBoundsException();
         }
-        return ref.getDoubleLE((int) index * Long.BYTES);
+        return ref.getDouble((int) index * Long.BYTES);
     }
 
     @Override
diff --git a/server/src/main/java/org/elasticsearch/common/util/ReleasableIntArray.java b/server/src/main/java/org/elasticsearch/common/util/ReleasableIntArray.java
index ea284c5a209..ff057b0d0c1 100644
--- a/server/src/main/java/org/elasticsearch/common/util/ReleasableIntArray.java
+++ b/server/src/main/java/org/elasticsearch/common/util/ReleasableIntArray.java
@@ -41,7 +41,7 @@ class ReleasableIntArray implements IntArray {
             // We can't serialize messages longer than 2gb anyway
             throw new ArrayIndexOutOfBoundsException();
         }
-        return ref.getIntLE((int) index * 4);
+        return ref.getInt((int) index * 4);
     }
 
     @Override
diff --git a/server/src/main/java/org/elasticsearch/common/util/ReleasableLongArray.java b/server/src/main/java/org/elasticsearch/common/util/ReleasableLongArray.java
index f6d82ce45d9..4cb86ba5f5c 100644
--- a/server/src/main/java/org/elasticsearch/common/util/ReleasableLongArray.java
+++ b/server/src/main/java/org/elasticsearch/common/util/ReleasableLongArray.java
@@ -42,7 +42,7 @@ public class ReleasableLongArray implements LongArray {
             // We can't serialize messages longer than 2gb anyway
             throw new ArrayIndexOutOfBoundsException();
         }
-        return ref.getLongLE((int) index * Long.BYTES);
+        return ref.getLong((int) index * Long.BYTES);
     }
 
     @Override
diff --git a/server/src/test/java/org/elasticsearch/common/bytes/BytesArrayTests.java b/server/src/test/java/org/elasticsearch/common/bytes/BytesArrayTests.java
index e067be6b1b0..e5fd8ffd855 100644
--- a/server/src/test/java/org/elasticsearch/common/bytes/BytesArrayTests.java
+++ b/server/src/test/java/org/elasticsearch/common/bytes/BytesArrayTests.java
@@ -108,4 +108,46 @@ public class BytesArrayTests extends AbstractBytesReferenceTestCase {
         assertThat(e.getMessage(), equalTo("Index 9 out of bounds for length 9"));
     }
 
+    public void testGetInt() {
+        BytesReference ref = new BytesArray(new byte[] { 0x00, 0x01, 0x00, 0x12, 0x10, 0x12 }, 1, 5);
+        assertThat(ref.getInt(0), equalTo(0x01001210));
+        assertThat(ref.getInt(1), equalTo(0x00121012));
+        Exception e = expectThrows(ArrayIndexOutOfBoundsException.class, () -> ref.getIntLE(2));
+        assertThat(e.getMessage(), equalTo("Index 3 out of bounds for length 3"));
+        /*
+         * Wait. 3!? The array has length 6. Well, the var handle stuff
+         * for arrays just subtracts three - because that's one more than
+         * the number of bytes in an int. Get it? I'm not sure I do either....
+         */
+    }
+
+    public void testGetLong() {
+        // first 8 bytes = 888, second 8 bytes = Long.MAX_VALUE
+        // tag::noformat
+        byte[] array = new byte[] {
+            0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x3, 0x78,
+            0x7F, -0x1, -0x1, -0x1, -0x1, -0x1, -0x1, -0x1
+        };
+        // end::noformat
+        BytesReference ref = new BytesArray(array, 0, array.length);
+        assertThat(ref.getLong(0), equalTo(888L));
+        assertThat(ref.getLong(8), equalTo(Long.MAX_VALUE));
+        Exception e = expectThrows(ArrayIndexOutOfBoundsException.class, () -> ref.getLongLE(9));
+        assertThat(e.getMessage(), equalTo("Index 9 out of bounds for length 9"));
+    }
+
+    public void testGetDouble() {
+        // first 8 bytes = 1.2, second 8 bytes = 1.4
+        // tag::noformat
+        byte[] array = new byte[] {
+            0x3F, -0xD, 0x33, 0x33, 0x33, 0x33, 0x33, 0x33,
+            0x3F, -0xA, 0x66, 0x66, 0x66, 0x66, 0x66, 0x66
+        };
+        // end::noformat
+        BytesReference ref = new BytesArray(array, 0, array.length);
+        assertThat(ref.getDouble(0), equalTo(1.2));
+        assertThat(ref.getDouble(8), equalTo(1.4));
+        Exception e = expectThrows(ArrayIndexOutOfBoundsException.class, () -> ref.getDoubleLE(9));
+        assertThat(e.getMessage(), equalTo("Index 9 out of bounds for length 9"));
+    }
 }
diff --git a/server/src/test/java/org/elasticsearch/common/bytes/CompositeBytesReferenceTests.java b/server/src/test/java/org/elasticsearch/common/bytes/CompositeBytesReferenceTests.java
index 1ff86d9b4bf..8d9ff66d436 100644
--- a/server/src/test/java/org/elasticsearch/common/bytes/CompositeBytesReferenceTests.java
+++ b/server/src/test/java/org/elasticsearch/common/bytes/CompositeBytesReferenceTests.java
@@ -229,4 +229,70 @@ public class CompositeBytesReferenceTests extends AbstractBytesReferenceTestCase
         assertThat(comp.getLongLE(16), equalTo(512L));
         expectThrows(IndexOutOfBoundsException.class, () -> comp.getLongLE(17));
     }
+
+    public void testGetInt() {
+        BytesReference[] refs = new BytesReference[] {
+            new BytesArray(new byte[] { 0x04, 0x03, 0x02, 0x01 }),
+            new BytesArray(new byte[] { 0x00, 0x12, 0x10, 0x12 }) };
+        BytesReference comp = CompositeBytesReference.of(refs);
+        assertThat(comp.getInt(0), equalTo(0x04030201));
+        assertThat(comp.getInt(1), equalTo(0x03020100));
+        assertThat(comp.getInt(2), equalTo(0x02010012));
+        assertThat(comp.getInt(3), equalTo(0x01001210));
+        assertThat(comp.getInt(4), equalTo(0x00121012));
+        // The jvm can optimize throwing ArrayIndexOutOfBoundsException by reusing the same exception,
+        // but these reused exceptions have no message or stack trace. This sometimes happens when running this test case.
+        // We can assert the exception message if -XX:-OmitStackTraceInFastThrow is set in gradle test task.
+        expectThrows(ArrayIndexOutOfBoundsException.class, () -> comp.getInt(5));
+    }
+
+    public void testGetDouble() {
+        // first double = 1.2, second double = 1.4, third double = 1.6
+        // tag::noformat
+        byte[] data = new byte[] {
+            0x3F, -0xD, 0x33, 0x33, 0x33, 0x33, 0x33, 0x33,
+            0x3F, -0xA, 0x66, 0x66, 0x66, 0x66, 0x66, 0x66,
+            0x3F, -0x7, -0x67, -0x67, -0x67, -0x67, -0x67, -0x66};
+        // end::noformat
+
+        List<BytesReference> refs = new ArrayList<>();
+        int bytesPerChunk = randomFrom(4, 16);
+        for (int offset = 0; offset < data.length; offset += bytesPerChunk) {
+            int length = Math.min(bytesPerChunk, data.length - offset);
+            refs.add(new BytesArray(data, offset, length));
+        }
+        BytesReference comp = CompositeBytesReference.of(refs.toArray(BytesReference[]::new));
+        assertThat(comp.getDouble(0), equalTo(1.2));
+        assertThat(comp.getDouble(8), equalTo(1.4));
+        assertThat(comp.getDouble(16), equalTo(1.6));
+        // The jvm can optimize throwing ArrayIndexOutOfBoundsException by reusing the same exception,
+        // but these reused exceptions have no message or stack trace. This sometimes happens when running this test case.
+        // We can assert the exception message if -XX:-OmitStackTraceInFastThrow is set in gradle test task.
+        expectThrows(IndexOutOfBoundsException.class, () -> comp.getDouble(17));
+    }
+
+    public void testGetLong() {
+        // first long = 2, second long = 44, third long = 512
+        // tag::noformat
+        byte[] data = new byte[] {
+            0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x2,
+            0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x2C,
+            0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x2, 0x0};
+        // end::noformat
+
+        byte[] d = new byte[8];
+        ByteUtils.writeLongBE(2, d, 0);
+
+        List<BytesReference> refs = new ArrayList<>();
+        int bytesPerChunk = randomFrom(4, 16);
+        for (int offset = 0; offset < data.length; offset += bytesPerChunk) {
+            int length = Math.min(bytesPerChunk, data.length - offset);
+            refs.add(new BytesArray(data, offset, length));
+        }
+        BytesReference comp = CompositeBytesReference.of(refs.toArray(BytesReference[]::new));
+        assertThat(comp.getLong(0), equalTo(2L));
+        assertThat(comp.getLong(8), equalTo(44L));
+        assertThat(comp.getLong(16), equalTo(512L));
+        expectThrows(IndexOutOfBoundsException.class, () -> comp.getLong(17));
+    }
 }
diff --git a/settings.gradle b/settings.gradle
index afb988dc9f4..b9b87a30fd0 100644
--- a/settings.gradle
+++ b/settings.gradle
@@ -61,11 +61,13 @@ List projects = [
   'distribution:archives:darwin-tar',
   'distribution:archives:darwin-aarch64-tar',
   'distribution:archives:linux-aarch64-tar',
+  'distribution:archives:linux-s390x-tar',
   'distribution:archives:linux-tar',
   'distribution:docker',
   'distribution:docker:cloud-ess-docker-export',
   'distribution:docker:cloud-ess-docker-aarch64-export',
   'distribution:docker:docker-aarch64-export',
+  'distribution:docker:docker-s390x-export',
   'distribution:docker:docker-export',
   'distribution:docker:ironbank-docker-aarch64-export',
   'distribution:docker:ironbank-docker-export',
@@ -74,8 +76,10 @@ List projects = [
   'distribution:docker:cloud-ess-fips-docker-export',
   'distribution:docker:cloud-ess-fips-docker-aarch64-export',
   'distribution:packages:aarch64-deb',
+  'distribution:packages:s390x-deb',
   'distribution:packages:deb',
   'distribution:packages:aarch64-rpm',
+  'distribution:packages:s390x-rpm',
   'distribution:packages:rpm',
   'distribution:bwc:bugfix',
   'distribution:bwc:bugfix2',
diff --git a/x-pack/plugin/esql/arrow/src/main/java/org/elasticsearch/xpack/esql/arrow/BlockConverter.java b/x-pack/plugin/esql/arrow/src/main/java/org/elasticsearch/xpack/esql/arrow/BlockConverter.java
index 2a305cfdbc5..da6b8bbc749 100644
--- a/x-pack/plugin/esql/arrow/src/main/java/org/elasticsearch/xpack/esql/arrow/BlockConverter.java
+++ b/x-pack/plugin/esql/arrow/src/main/java/org/elasticsearch/xpack/esql/arrow/BlockConverter.java
@@ -104,7 +104,7 @@ public abstract class BlockConverter {
                 // TODO could we "just" get the memory of the array and dump it?
                 int count = BlockConverter.valueCount(block);
                 for (int i = 0; i < count; i++) {
-                    out.writeDoubleLE(block.getDouble(i));
+                    out.writeDouble(block.getDouble(i));
                 }
                 return (long) count * Double.BYTES;
             });
@@ -142,7 +142,7 @@ public abstract class BlockConverter {
                 // TODO could we "just" get the memory of the array and dump it?
                 int count = BlockConverter.valueCount(block);
                 for (int i = 0; i < count; i++) {
-                    out.writeIntLE(block.getInt(i));
+                    out.writeInt(block.getInt(i));
                 }
                 return (long) count * Integer.BYTES;
             });
@@ -183,7 +183,7 @@ public abstract class BlockConverter {
                 // TODO could we "just" get the memory of the array and dump it?
                 int count = BlockConverter.valueCount(block);
                 for (int i = 0; i < count; i++) {
-                    out.writeLongLE(block.getLong(i));
+                    out.writeLong(block.getLong(i));
                 }
                 return (long) count * Long.BYTES;
             });
@@ -260,7 +260,7 @@ public abstract class BlockConverter {
                 if (block.areAllValuesNull()) {
                     var count = valueCount(block) + 1;
                     for (int i = 0; i < count; i++) {
-                        out.writeIntLE(0);
+                        out.writeInt(0);
                     }
                     return offsetvectorByteSize(block);
                 }
@@ -269,14 +269,14 @@ public abstract class BlockConverter {
                 BytesRef scratch = new BytesRef();
                 int offset = 0;
                 for (int i = 0; i < valueCount(block); i++) {
-                    out.writeIntLE(offset);
+                    out.writeInt(offset);
                     // FIXME: add a ByteRefsVector.getLength(position): there are some cases
                     // where getBytesRef will allocate, which isn't needed here.
                     BytesRef v = block.getBytesRef(i, scratch);
 
                     offset += v.length;
                 }
-                out.writeIntLE(offset);
+                out.writeInt(offset);
                 return offsetvectorByteSize(block);
             });
 
@@ -524,11 +524,11 @@ public abstract class BlockConverter {
                 // '<=' is intentional to write the end position of the last item
                 for (int i = 0; i <= block.getPositionCount(); i++) {
                     // TODO could we get the block's firstValueIndexes and dump it?
-                    out.writeIntLE(block.getFirstValueIndex(i));
+                    out.writeInt(block.getFirstValueIndex(i));
                 }
             } else {
                 for (int i = 0; i <= block.getPositionCount(); i++) {
-                    out.writeIntLE(i);
+                    out.writeInt(i);
                 }
             }
 
